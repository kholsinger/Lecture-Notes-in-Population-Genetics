<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Analyzing the genetic structure of populations</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="pandoc.css" />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Analyzing the genetic structure of populations</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#a-numerical-example" id="toc-a-numerical-example">A
numerical example</a></li>
<li><a href="#the-algebraic-development"
id="toc-the-algebraic-development">The algebraic development</a></li>
<li><a href="#wrights-f-statistics"
id="toc-wrights-f-statistics">Wright’s <span
class="math inline">\(F\)</span>-statistics</a></li>
<li><a href="#estimating-f-statistics"
id="toc-estimating-f-statistics">Estimating <span
class="math inline">\(F\)</span>-statistics</a></li>
<li><a href="#an-example-from-isotoma-petraea"
id="toc-an-example-from-isotoma-petraea">An example from
<span><em>Isotoma petraea</em></span></a>
<ul>
<li><a href="#summary" id="toc-summary">Summary</a></li>
</ul></li>
<li><a href="#statistical-expectation-and-unbiased-estimates"
id="toc-statistical-expectation-and-unbiased-estimates">Statistical
expectation and unbiased estimates</a>
<ul>
<li><a href="#the-gory-details" id="toc-the-gory-details">The gory
details</a></li>
</ul></li>
<li><a href="#corrections-for-sampling-error"
id="toc-corrections-for-sampling-error">Corrections for sampling
error</a>
<ul>
<li><a href="#neis-g_st" id="toc-neis-g_st">Nei’s <span
class="math inline">\(G_{st}\)</span></a></li>
<li><a href="#weir-and-cockerhams-theta"
id="toc-weir-and-cockerhams-theta">Weir and Cockerham’s <span
class="math inline">\(\theta\)</span></a>
<ul>
<li><a href="#even-more-gory-details"
id="toc-even-more-gory-details">Even more gory details</a></li>
</ul></li>
<li><a href="#applying-g_st-and-theta"
id="toc-applying-g_st-and-theta">Applying <span
class="math inline">\(G_{st}\)</span> and <span
class="math inline">\(\theta\)</span></a></li>
</ul></li>
<li><a href="#an-example-from-wright" id="toc-an-example-from-wright">An
example from Wright</a>
<ul>
<li><a href="#results" id="toc-results">Results</a></li>
<li><a href="#interpretation"
id="toc-interpretation">Interpretation</a></li>
</ul></li>
<li><a href="#reichs-f-statistics" id="toc-reichs-f-statistics">Reich’s
<span class="math inline">\(f\)</span>-statistics</a></li>
<li><a href="#creative-commons-license"
id="toc-creative-commons-license">Creative Commons License</a></li>
</ul>
</nav>
<h1 class="unnumbered" id="introduction">Introduction</h1>
<p>So far we’ve focused on inbreeding as one important way that
populations may fail to mate at random, but there’s another way in which
virtually all populations and species fail to mate at random.
Individuals tend to mate with those that are nearby. Even within a
fairly small area, phenomena like nearest neighbor pollination in
flowering plants or home-site fidelity in animals can cause mates to be
selected in a geographically non-random way. What are the population
genetic consequences of this form of non-random mating?</p>
<p>Well, if you think about it a little, you can probably figure it out.
Since individuals that occur close to one another tend to be more
genetically similar than those that occur far apart, the impacts of
local mating will mimic those of inbreeding within a single, well-mixed
population.</p>
<h1 class="unnumbered" id="a-numerical-example">A numerical example</h1>
<p>For example, suppose we have two subpopulations of green lacewings,
one of which occurs in forests the other of which occurs in adjacent
meadows.<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> Suppose further that within each
subpopulation mating occurs completely at random, but that there is no
mating between forest and meadow individuals. Suppose we’ve determined
allele frequencies in each population at a locus coding for
phosphoglucoisomerase (<span class="math inline">\(PGI\)</span>), which
conveniently has only two alleles. The frequency of <span
class="math inline">\(A_1\)</span> in the forest is 0.4 and in the
meadow in 0.7. We can easily calculate the expected genotype frequencies
within each population, namely</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Forest</td>
<td style="text-align: right;">0.16</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0.36</td>
</tr>
<tr class="even">
<td style="text-align: left;">Meadow</td>
<td style="text-align: right;">0.49</td>
<td style="text-align: right;">0.42</td>
<td style="text-align: right;">0.09</td>
</tr>
</tbody>
</table>
</div>
<p>Suppose, however, we were to consider a combined population
consisting of 100 individuals from the forest subpopulation and 100
individuals from the meadow subpopulation. Then we’d get the
following:<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<div class="center">
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">From forest</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">48</td>
<td style="text-align: right;">36</td>
</tr>
<tr class="even">
<td style="text-align: left;">From meadow</td>
<td style="text-align: right;">49</td>
<td style="text-align: right;">42</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">90</td>
<td style="text-align: right;">45</td>
</tr>
</tbody>
</table>
</div>
<p>So the frequency of <span class="math inline">\(A_1\)</span> is <span
class="math inline">\((2(65) + 90)/(2(65 + 90 + 45)) =
0.55\)</span>. Notice that this is just the average allele frequency in
the two subpopulations, i.e., <span class="math inline">\((0.4 +
0.7)/2\)</span>. Since each subpopulation has genotypes in
Hardy-Weinberg proportions, you might expect the combined population to
have genotypes in Hardy-Weinberg proportions, but if you did you’d be
wrong. Just look.</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Expected (from <span
class="math inline">\(p=0.55\)</span>)</td>
<td style="text-align: right;">(0.3025)200</td>
<td style="text-align: right;">(0.4950)200</td>
<td style="text-align: right;">(0.2025)200</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: right;">60.5</td>
<td style="text-align: right;">99.0</td>
<td style="text-align: right;">40.5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Observed (from table above)</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">90</td>
<td style="text-align: right;">45</td>
</tr>
</tbody>
</table>
</div>
<p>The expected and observed don’t match, even though there is random
mating within both subpopulations. They don’t match because there isn’t
random mating <span><em>in the combined population</em></span>, only
within each subpopulation. Forest lacewings choose mates at random from
other forest lacewings, but they never mate with a meadow lacewing (and
<span> <em>vice versa</em></span>). Our sample includes two populations
that don’t mix. As a result, heterozygotes in our combined sample are
less frequent (<span class="math inline">\(0.45\)</span> vs <span
class="math inline">\(0.495\)</span>) than we’d expect if the population
were well mixed with an allelel frequency of <span
class="math inline">\(0.55\)</span>. This is an example of what’s known
as the <span><em>Wahlund effect</em></span> <span class="citation"
data-cites="Wahlund-1928"></span>.</p>
<h1 class="unnumbered" id="the-algebraic-development">The algebraic
development</h1>
<p>Even though you’ve only known me for a couple of weeks now, you
should know me well enough to know that I’m not going to be satisfied
with a numerical example. You should know that I now feel the need to do
some algebra to describe this situation a little more generally.</p>
<p>Suppose we know allele frequencies in <span
class="math inline">\(k\)</span> subpopulations.<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Let
<span class="math inline">\(p_i\)</span> be the frequency of <span
class="math inline">\(A_1\)</span> in the <span
class="math inline">\(i\)</span>th subpopulation. Then if we assume that
all subpopulations contribute equally to combined population,<a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> we can calculate expected and
observed genotype frequencies the way we did above:</p>
<div class="center">
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span
class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Expected</td>
<td style="text-align: right;"><span class="math inline">\(\bar
p^2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(2\bar p\bar
q\)</span></td>
<td style="text-align: right;"><span class="math inline">\(\bar
q^2\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Observed</td>
<td style="text-align: right;"><span
class="math inline">\(\frac{1}{k}\sum p_i^2\)</span></td>
<td style="text-align: right;"><span
class="math inline">\(\frac{1}{k}\sum 2p_iq_i\)</span></td>
<td style="text-align: right;"><span
class="math inline">\(\frac{1}{k}\sum q_i^2\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>where <span class="math inline">\(\bar p = \sum p_i/k\)</span> and
<span class="math inline">\(\bar q = 1 - \bar p\)</span> are the average
allele frequencies in the combined sample. Now <span
class="math display">\[\begin{aligned}
\frac{1}{k}\sum p_i^2 &amp;=&amp; \frac{1}{k}\sum (p_i - \bar p + \bar
p)^2 \\
&amp;=&amp; \frac{1}{k}\sum \left((p_i - \bar p)^2 + 2\bar p(p_i - \bar
p)
                            + \bar p^2\right) \\
             &amp;=&amp; \frac{1}{k}\sum (p_i - \bar p)^2 + \bar p^2 \\
             &amp;=&amp; \hbox{Var}(p) + \bar p^2 \label{eq:p2}
\end{aligned}\]</span> Similarly, <span
class="math display">\[\begin{aligned}
\frac{1}{k}\sum 2p_iq_i &amp;=&amp; 2\bar p\bar q - 2\hbox{Var}(p)
\label{eq:2pq} \\
\frac{1}{k}\sum q_i^2   &amp;=&amp; \bar q^2 + \hbox{Var}(p)
\label{eq:q2}
\end{aligned}\]</span></p>
<p>Since <span class="math inline">\(\hbox{Var}(p) \ge 0\)</span> by
definition, with equality holding only when all subpopulations have the
same allele frequency, we can conclude that</p>
<ul>
<li><p>Homozygotes will be more frequent and heterozygotes will be less
frequent than expected based on the allele frequency in the combined
population.</p></li>
<li><p>The magnitude of the departure from expectations is directly
related to the magnitude of the variance in allele frequencies across
populations, <span
class="math inline">\(\hbox{Var}(p)\)</span>.</p></li>
<li><p>The effect will apply to <span><em>any</em></span> mixing of
samples in which the subpopulations combined have different allele
frequencies.<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p></li>
<li><p>The same general phenomenon will occur if there are multiple
alleles at a locus, although it is possible for one or a few
heterozygotes to be <span><em>more</em></span> frequent than expected if
there is positive covariance in the constituent allele frequencies
across populations.<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></p></li>
<li><p>The effect is analogous to inbreeding. Homozygotes are more
frequent and heterozygotes are less frequent than expected.<a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p></li>
</ul>
<p>To return to our earlier numerical example:</p>
<p><span class="math display">\[\begin{aligned}
\hbox{Var}(p) &amp;=&amp; \left((0.4 - 0.55)^2 + (0.7 - 0.55)^2\right)/2
\\
              &amp;=&amp; 0.0225
\end{aligned}\]</span></p>
<div class="center">
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Expected</th>
<th style="text-align: center;"></th>
<th style="text-align: right;"></th>
<th style="text-align: center;"></th>
<th style="text-align: right;">Observed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(A_1A_1\)</span></td>
<td style="text-align: right;">0.3025</td>
<td style="text-align: center;">+</td>
<td style="text-align: right;">0.0225</td>
<td style="text-align: center;">=</td>
<td style="text-align: right;">0.3250</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span
class="math inline">\(A_1A_2\)</span></td>
<td style="text-align: right;">0.4950</td>
<td style="text-align: center;">-</td>
<td style="text-align: right;">2(0.0225)</td>
<td style="text-align: center;">=</td>
<td style="text-align: right;">0.4500</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span
class="math inline">\(A_2A_2\)</span></td>
<td style="text-align: right;">0.2025</td>
<td style="text-align: center;">+</td>
<td style="text-align: right;">0.0225</td>
<td style="text-align: center;">=</td>
<td style="text-align: right;">0.2250</td>
</tr>
</tbody>
</table>
</div>
<h1 class="unnumbered" id="wrights-f-statistics">Wright’s <span
class="math inline">\(F\)</span>-statistics</h1>
<p>One limitation of the way I’ve described things so far is that <span
class="math inline">\(\hbox{Var}(p)\)</span> doesn’t provide a
convenient way to compare population structure from different samples.
<span class="math inline">\(\hbox{Var}(p)\)</span> can be much larger if
both alleles are about equally common in the whole sample than if one
occurs at a mean frequency of 0.99 and the other at a frequency of 0.01.
Moreover, if you stare at equations (<a href="#eq:p2"
data-reference-type="ref" data-reference="eq:p2">[eq:p2]</a>)–(<a
href="#eq:q2" data-reference-type="ref"
data-reference="eq:q2">[eq:q2]</a>) for a while, you begin to realize
that they look a lot like some equations we’ve already encountered.
Namely, if we were to define <span
class="math inline">\(F_{st}\)</span><a href="#fn8" class="footnote-ref"
id="fnref8" role="doc-noteref"><sup>8</sup></a> as <span
class="math inline">\(\mbox{Var}(p)/\bar p\bar q\)</span>, then we could
rewrite equations (<a href="#eq:p2" data-reference-type="ref"
data-reference="eq:p2">[eq:p2]</a>)–(<a href="#eq:q2"
data-reference-type="ref" data-reference="eq:q2">[eq:q2]</a>) as <span
class="math display">\[\begin{aligned}
\frac{1}{k}\sum p_i^2 &amp;=&amp; \bar p^2 + F_{st}\bar p \bar q
\label{eq:p2-f} \\
\frac{1}{k}\sum 2p_iq_i &amp;=&amp; 2\bar p\bar q(1 - F_{st})
\label{eq:2pq-f} \\
\frac{1}{k}\sum q_i^2   &amp;=&amp; \bar q^2 + F_{st}\bar p \bar q
\label{eq:q2-f}
\end{aligned}\]</span> And it’s not even completely artificial to define
<span class="math inline">\(F_{st}\)</span> the way I did. After all,
the effect of geographic structure is to cause matings to occur among
genetically similar individuals. It’s rather like inbreeding.<a
href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a> Moreover, the extent to which this
local mating matters depends on the extent to which populations differ
from one another. It turns out that <span class="math inline">\(\bar
p\bar q\)</span> is the maximum allele frequency variance possible,
given the observed mean frequency. So one way of thinking about <span
class="math inline">\(F_{st}\)</span> is that it measures the amount of
allele frequency variance in a sample relative to the maximum
possible.<a href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></p>
<p>There may, of course, be inbreeding within populations, too. But it’s
easy to incorporate this into the framework, too.<a href="#fn11"
class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>
Let <span class="math inline">\(H_i\)</span> be the actual
heterozygosity in individuals within subpopulations, <span
class="math inline">\(H_s\)</span> be the expected heterozygosity within
subpopulations assuming Hardy-Weinberg within populations, and <span
class="math inline">\(H_t\)</span> be the expected heterozygosity in the
combined population assuming Hardy-Weinberg over the whole sample.<a
href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a> Then thinking of <span
class="math inline">\(f\)</span> as a measure of departure from
Hardy-Weinberg and assuming that all populations depart from
Hardy-Weinberg to the same degree, i.e., that they all have the same
<span class="math inline">\(f\)</span>, we can define <span
class="math display">\[F_{it} = 1 - \frac{H_i}{H_t} \quad .\]</span>
<span class="math inline">\(F_{it}\)</span> is the overall departure
from Hardy-Weinberg in the entire sample. Let’s fiddle with <span
class="math inline">\(F_{ST}\)</span> a bit.<a href="#fn13"
class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>
<span class="math display">\[\begin{aligned}
1 - F_{it} &amp;=&amp; \frac{H_i}{H_t} \\
           &amp;=&amp;
\left(\frac{H_i}{H_s}\right)\left(\frac{H_s}{H_t}\right) \\
           &amp;=&amp; (1 - F_{is})(1 - F_{st}) \quad ,
\end{aligned}\]</span> where <span class="math inline">\(F_{is}\)</span>
is the inbreeding coefficient within populations, i.e., <span
class="math inline">\(f\)</span>, and <span
class="math inline">\(F_{st}\)</span> has the same definition as
before.<a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a> <span
class="math inline">\(H_t\)</span> is often referred to as the genetic
diversity in a population. So another way of thinking about <span
class="math inline">\(F_{st} =
(H_t - H_s)/H_t\)</span> is that it’s the proportion of the diversity in
the sample that’s due to allele frequency differences among
populations.</p>
<h1 class="unnumbered" id="estimating-f-statistics">Estimating <span
class="math inline">\(F\)</span>-statistics</h1>
<p>We’ve now seen the principles underlying Wright’s <span
class="math inline">\(F\)</span>-statistics. I should point out that
Gustave Mal<span>é</span>cot developed very similar ideas at about the
same time as Wright, but since Wright’s notation stuck,<a href="#fn15"
class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>
population geneticists generally refer to statistics like those we’ve
discussed as Wright’s <span
class="math inline">\(F\)</span>-statistics.<a href="#fn16"
class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<p>Neither Wright nor Mal<span>é</span>cot worried too much about the
problem of estimating <span class="math inline">\(F\)</span>-statistics
from data. Both realized that any inferences about population structure
are based on a sample and that the characteristics of the sample may
differ from those of the population from which it was drawn, but neither
developed any explicit way of dealing with those differences. Wright
develops some very <span><em>ad hoc</em></span> approaches in his
book <span class="citation" data-cites="Wright69"></span>, but they have
been forgotten, which is good because they aren’t satisfactory and they
shouldn’t be used. There are now three reasonable approaches
available:<a href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a></p>
<ol>
<li><p>Nei’s <span class="math inline">\(G\)</span>-statistics,</p></li>
<li><p>Weir and Cockerham’s <span
class="math inline">\(\theta\)</span>-statistics, and</p></li>
<li><p>A Bayesian analog of <span
class="math inline">\(\theta\)</span>.<a href="#fn18"
class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a></p></li>
</ol>
<h1 class="unnumbered" id="an-example-from-isotoma-petraea">An example
from <span><em>Isotoma petraea</em></span></h1>
<p>To make the differences in implementation and calculation clear, I’m
going to use data from 12 populations of <span><em>Isotoma
petraea</em></span> in southwestern Australia surveyed for genotype at
<span> <em>GOT</em></span>–1 <span class="citation"
data-cites="James-etal-1983"></span> as an example throughout these
discussions (Table <a href="#table:isotoma" data-reference-type="ref"
data-reference="table:isotoma">1</a>).</p>
<div class="center">
<div id="table:isotoma">
<table>
<caption>Genotype counts at the <span
class="math inline">\(GOT-1\)</span> locus in <span><em>Isotoma
petraea</em></span> (from <span class="citation"
data-cites="James-etal-1983"></span>).</caption>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td colspan="3" style="text-align: center;">Genotype</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Population</td>
<td style="text-align: right;"><span
class="math inline">\(A_{1}A_{1}\)</span></td>
<td style="text-align: right;"><span
class="math inline">\(A_{1}A_{2}\)</span></td>
<td style="text-align: right;"><span
class="math inline">\(A_{2}A_{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\hat
p\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Yackeyackine Soak</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Gnarlbine Rock</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">0.7750</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Boorabbin</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">0.8000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Bullabulling</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Mt. Caudan</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Victoria Rock</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">0.8500</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Yellowdine</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: center;">0.8167</td>
</tr>
<tr class="even">
<td style="text-align: center;">Wargangering</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
<td style="text-align: center;">0.9242</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Wagga Rock</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: center;">“Iron Knob Major”</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Rainy Rocks</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">0.5000</td>
</tr>
<tr class="even">
<td style="text-align: center;">“Rainy Rocks Major”</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Let’s ignore the sampling problem for a moment and calculate the
<span class="math inline">\(F\)</span>-statistics as if we had observed
the population allele frequencies without error. They’ll serve as our
baseline for comparison. <span class="math display">\[\begin{aligned}
\bar p &amp;=&amp; 0.8888 \\
\hbox{Var}(p) &amp;=&amp; 0.02118 \\
F_{st} &amp;=&amp; 0.2143 \\
\hbox{Individual heterozygosity} &amp;=&amp; (0.0000 + 0.1500 + 0.1000 +
                                      0.0000 + 0.0000 + 0.1667 +
                                      0.1000 \\
                                 &amp;&amp;   + 0.0909 + 0.0000 +
                                      0.0000 + 1.0000 + 0.0000)/12 \\
                           &amp;=&amp; 0.1340 \\
\hbox{Expected heterozygosity} &amp;=&amp; 2(0.8888)(1 - 0.8888) \\
                           &amp;=&amp; 0.1976 \\
F_{it} &amp;=&amp; 1 - \frac{\hbox{Individual heterozygosity}}%
                    {\hbox{Expected heterozygosity}} \\
                  &amp;=&amp; 1 - \frac{0.1340}{0.1976} \\
                  &amp;=&amp; 0.3221 \\
       1 - F_{it} &amp;=&amp; (1 - F_{is})(1 - F_{st}) \\
           F_{is} &amp;=&amp; \frac{F_{it} - F_{st}}{1 - F_{st}} \\
                  &amp;=&amp; \frac{0.3221 - 0.2143}{1 - 0.2143} \\
                  &amp;=&amp; 0.1372
\end{aligned}\]</span></p>
<h2 class="unnumbered" id="summary">Summary</h2>
<div class="center">
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes due to inbreeding
within subpopulations (<span
class="math inline">\(F_{is}\)</span>):</td>
<td style="text-align: center;">0.1372</td>
</tr>
<tr class="even">
<td style="text-align: left;">Correlation of gametes within
subpopulations (<span class="math inline">\(F_{st}\)</span>):</td>
<td style="text-align: center;">0.2143</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes in sample (<span
class="math inline">\(F_{it}\)</span>):</td>
<td style="text-align: center;">0.3221</td>
</tr>
</tbody>
</table>
</div>
<p>Why do I refer to them as the “correlation of gametes <span
class="math inline">\(\dots\)</span>”? There are two reasons:</p>
<ol>
<li><p>That’s the way Wright always referred to and interpreted
them.</p></li>
<li><p>We can define indicator variables <span
class="math inline">\(x_{ijk} = 1\)</span> if the <span
class="math inline">\(i\)</span>th allele in the <span
class="math inline">\(jth\)</span> individual of population <span
class="math inline">\(k\)</span> is <span
class="math inline">\(A_1\)</span> and <span
class="math inline">\(x_{ijk} = 0\)</span> if that allele is not <span
class="math inline">\(A_1\)</span>. This may seem like a strange thing
to do, but the Weir and Cockerham approach to <span
class="math inline">\(F\)</span>-statistics described below uses just
such an approach. If we do this, then the definitions for <span
class="math inline">\(F_{is}\)</span>, <span
class="math inline">\(F_{st}\)</span>, and <span
class="math inline">\(F_{it}\)</span> follow directly.<a href="#fn19"
class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a></p></li>
</ol>
<p>Notice that <span class="math inline">\(F_{is}\)</span> could be
negative, i.e., there could be an <span> <em>excess</em></span> of
heterozygotes within populations (<span class="math inline">\(F_{is}
&lt; 0\)</span>). Notice also that we’re implicitly assuming that the
extent of departure from Hardy-Weinberg proportions is the same in all
populations. Equivalently, we can regard <span
class="math inline">\(F_{is}\)</span> as the <span>
<em>average</em></span> departure from Hardy-Weinberg proportions across
all populations.</p>
<h1 class="unnumbered"
id="statistical-expectation-and-unbiased-estimates">Statistical
expectation and unbiased estimates</h1>
<p>So far I’ve assumed that we know the allele frequencies without
error, but of course that’s never the case unless we’ve created
experimental populations. We are always taking a sample from a
population and inferringestimatingallele frequencies from our sample.
Similarly, we are <span><em>estimating</em></span> <span
class="math inline">\(F_{ST}\)</span> and our <span>
<em>estimate</em></span> of <span class="math inline">\(F_{ST}\)</span>
needs to take account of the imprecision in the allele frequency
estimates on which it was based. To understand one approach to dealing
with this uncertainty I need to introduce two new concepts:
<span><em>statistical expectation</em></span> and <span><em>unbiased
estimates</em></span>.</p>
<p>The concept of statistical expectation is actually quite an easy one.
It is an arithmetic average, just one calculated from probabilities
instead of being calculated from samples. So, for example, let <span
class="math inline">\(\mbox{P}(k|p,N)\)</span> be the probability that
we find <span class="math inline">\(k\)</span> <span
class="math inline">\(A_1\)</span> alleles in our sample of size <span
class="math inline">\(N\)</span> given that the allele frequency in the
population is <span class="math inline">\(p\)</span>. Then the
<span><em>expected number</em></span> of <span
class="math inline">\(A_1\)</span> alleles in our sample is just <span
class="math display">\[\begin{aligned}
\mbox{E}(k) &amp;=&amp; \sum_{k=0}^n k \mbox{P}(k|p,N) \\
     &amp;=&amp; n p \quad  \\
\end{aligned}\]</span> where <span class="math inline">\(n\)</span> is
the total number of alleles in our sample.<a href="#fn20"
class="footnote-ref" id="fnref20"
role="doc-noteref"><sup>20</sup></a></p>
<p>Now consider the expected value of our sample estimate of the
population allele frequency, <span class="math inline">\(\hat p =
k/n\)</span>, where <span class="math inline">\(k\)</span> now refers to
the number of <span class="math inline">\(A_1\)</span> alleles we
actually found. <span class="math display">\[\begin{aligned}
\mbox{E}(\hat p) &amp;=&amp; \mbox{E}\left(\sum_{k=1}^n (k/n)\right) \\
          &amp;=&amp; \sum_{k=1}^n (k/n) P(k|p,N) \\
          &amp;=&amp; (1/n)\left(\sum_{k=1}^n k P(k|p,N)\right) \\
          &amp;=&amp; (1/n)(n p) \\
          &amp;=&amp; p \quad . \\
\end{aligned}\]</span> Because <span class="math inline">\(\mbox{E}(\hat
p) = p\)</span>, <span class="math inline">\(\hat p\)</span> is said to
be an <span> <em>unbiased estimate</em></span> of <span
class="math inline">\(p\)</span>.<a href="#fn21" class="footnote-ref"
id="fnref21" role="doc-noteref"><sup>21</sup></a> When an estimate is
unbiased it means that if we were to repeat the sampling experiment an
infinite number of times and to take the average of the estimates, the
average of those values would be equal to the (unknown) parameter
value.</p>
<p>What about estimating the frequency of heterozygotes within a
population? The obvious estimator is <span class="math inline">\(\tilde
H = 2\hat p (1 - \hat
p)\)</span>. Well, <span class="math display">\[\begin{aligned}
\mbox{E}(\tilde H) &amp;=&amp; \mbox{E}\left(2\hat p (1 - \hat p)\right)
\\
     &amp;=&amp; 2\left(\mbox{E}(\hat p) - \mbox{E}({\hat p}^2)\right)
\\
     &amp;=&amp; \mbox{TAMO} \\
     &amp;=&amp; ((n-1)/n)2p(1-p) \quad . \\
\end{aligned}\]</span> Because <span
class="math inline">\(\mbox{E}(\tilde H) \ne 2p(1-p)\)</span>, <span
class="math inline">\(\tilde H\)</span> is a <span><em>biased
estimate</em></span> of <span class="math inline">\(2p(1-p)\)</span>.
If, however, we set <span class="math inline">\(\hat H = (n/(n-1))\tilde
H\)</span>, however, <span class="math inline">\(\hat H\)</span> is an
unbiased estimator of <span class="math inline">\(2p(1-p)\)</span>.<a
href="#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a></p>
<p>If you’ve ever wondered why you typically divide the sum of squared
deviations about the mean by <span class="math inline">\(n-1\)</span>
instead of <span class="math inline">\(n\)</span> when estimating the
variance of a sample, this is why. Dividing by <span
class="math inline">\(n\)</span> gives you a (slightly) biased
estimator.</p>
<h2 class="unnumbered" id="the-gory-details">The gory details<a
href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a></h2>
<p>Starting where we left off above: <span
class="math display">\[\begin{aligned}
\mbox{E}(\tilde H) &amp;=&amp; 2\left((\mbox{E}\hat p) - \mbox{E}({\hat
p}^2)\right) \\
     &amp;=&amp; 2\left(p - \mbox{E}\left((k/n)^2\right)\right) \quad ,
\end{aligned}\]</span> where <span class="math inline">\(k\)</span> is
the number of <span class="math inline">\(A_1\)</span> alleles in our
sample and <span class="math inline">\(n\)</span> is the sample size.
<span class="math display">\[\begin{aligned}
\mbox{E}\left((k/n)^2\right) &amp;=&amp; \sum (k/n)^2 \mbox{P}(k|p,N) \\
                      &amp;=&amp; (1/n)^2 \sum k^2 \mbox{P}(k|p,N) \\
                      &amp;=&amp; (1/n)^2 \left(\mbox{Var}(k) + \bar
k^2\right) \\
                      &amp;=&amp; (1/n)^2 \left(np(1-p) + n^2p^2\right)
\\
                      &amp;=&amp; p(1-p)/n + p^2 \quad .
\end{aligned}\]</span> Substituting this back into the equation above
yields the following: <span class="math display">\[\begin{aligned}
\mbox{E}(\tilde H) &amp;=&amp; 2\left(p - \left(p(1-p)/n +
p^2\right)\right) \\
     &amp;=&amp; 2\left(p(1-p) - p(1-p)/n\right) \\
     &amp;=&amp; \left(1 - 1/n\right)2p(1-p) \\
     &amp;=&amp; ((n-1)/n)2p(1-p) \quad . \\
\end{aligned}\]</span></p>
<h1 class="unnumbered" id="corrections-for-sampling-error">Corrections
for sampling error</h1>
<p>There are two sources of allele frequency difference among
subpopulations in our sample: (1) real differences in the allele
frequencies among our sampled subpopulations and (2) differences that
arise because allele frequencies in our samples differ from those in the
subpopulations from which they were taken.<a href="#fn24"
class="footnote-ref" id="fnref24"
role="doc-noteref"><sup>24</sup></a></p>
<h2 class="unnumbered" id="neis-g_st">Nei’s <span
class="math inline">\(G_{st}\)</span></h2>
<p>Nei and Chesser <span class="citation"
data-cites="Nei-Chesser-1983"></span> described one approach to
accounting for sampling error. So far as I’ve been able to determine,
there aren’t any currently supported programs<a href="#fn25"
class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a>
that calculate the bias-corrected versions of <span
class="math inline">\(G_{st}\)</span>.<a href="#fn26"
class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a> I
calculated the results in Table <a href="#table:fst-comparison"
data-reference-type="ref" data-reference="table:fst-comparison">2</a> by
hand.</p>
<p>The calculations are tedious, which is why you’ll want to find some
way of automating the calculations if you want to do them.<a
href="#fn27" class="footnote-ref" id="fnref27"
role="doc-noteref"><sup>27</sup></a> <span
class="math display">\[\begin{aligned}
H_{i} &amp;=&amp; 1 - {1 \over N} \sum_{k=1}^{N} \sum_{i=1}^{m}
{X_{kii}} \\
H_{s} &amp;=&amp; {\tilde n \over {\tilde n - 1}}
         \left[1 - \sum_{i=1}^{m} {\bar {\hat x_{i}^{2}}}
         - {H_{I} \over {2 \tilde n}}\right] \\
H_{t} &amp;=&amp; 1 - \sum_{i=1}^{m} {\bar x_{i}^{2}} + {H_{S} \over
{\tilde n}}
         - {H_{I} \over {2 \tilde n N}}
\end{aligned}\]</span> where we have <span
class="math inline">\(N\)</span> subpopulations, <span
class="math inline">\({\bar {\hat x_{i}^{2}}} = \sum_{k=1}^{N}
{x_{ki}^{2}}/N\)</span>, <span class="math inline">\({\bar x_{i}} =
\sum_{k=1}^{N} x_{ki}/N\)</span>, <span class="math inline">\(\tilde
n\)</span> is the harmonic mean of the population sample sizes, i.e.,
<span class="math inline">\(\tilde n = \frac{1}{\frac{1}{N}
\sum_{k=1}^{N} \frac{1}{n_k}}\)</span>, <span
class="math inline">\(X_{kii}\)</span> is the frequency of genotype
<span class="math inline">\(A_{i}A_{i}\)</span> in population <span
class="math inline">\(k\)</span>, <span
class="math inline">\(x_{ki}\)</span> is the frequency of allele <span
class="math inline">\(A_{i}\)</span> in population <span
class="math inline">\(k\)</span>, and <span
class="math inline">\(n_k\)</span> is the sample size from population
<span class="math inline">\(k\)</span>. Recall that <span
class="math display">\[\begin{aligned}
F_{is} &amp;=&amp; 1 - {H_{i} \over H_{s}} \\
F_{st} &amp;=&amp; 1 - {H_{s} \over H_{t}} \\
F_{it} &amp;=&amp; 1 - {H_{i} \over H_{t}} \quad .
\end{aligned}\]</span></p>
<h2 class="unnumbered" id="weir-and-cockerhams-theta">Weir and
Cockerham’s <span class="math inline">\(\theta\)</span></h2>
<p>Weir and Cockerham <span class="citation"
data-cites="WeirCockerham84"></span> describe the fundamental ideas
behind this approach. Weir and Hill <span class="citation"
data-cites="Weir-Hill-2002"></span> bring things up to date. Holsinger
and Weir <span class="citation" data-cites="Holsinger-Weir-2009"></span>
provide a less technical overview.<a href="#fn28" class="footnote-ref"
id="fnref28" role="doc-noteref"><sup>28</sup></a> Most, if not all,
packages available now that estimate <span
class="math inline">\(F_{ST}\)</span> provide estimates of <span
class="math inline">\(\theta\)</span>. The most important difference
between <span class="math inline">\(\theta\)</span> and <span
class="math inline">\(G_{st}\)</span> and the reason why <span
class="math inline">\(G_{st}\)</span> has fallen into disuse is that
<span class="math inline">\(G_{st}\)</span> ignores an important source
of sampling error that <span class="math inline">\(\theta\)</span>
incorporates.</p>
<p>In many applications, especially in evolutionary biology, the
subpopulations included in our sample are not an exhasutive sample of
all populations. Moreover, even if we have sampled from every population
there is now, we may not have sampled from every population there ever
was. And even if we’ve sampled from every population there ever was, we
know that there are random elements in any evolutionary process. Thus,
if we could run the clock back and start it over again, the genetic
composition of the populations we have might be rather different from
that of the populations we sampled. In other words, our populations are,
in many cases, best regarded as a random sample from a much larger set
of populations that could have been sampled.</p>
<h3 class="unnumbered" id="even-more-gory-details">Even more gory
details<a href="#fn29" class="footnote-ref" id="fnref29"
role="doc-noteref"><sup>29</sup></a></h3>
<p>Let <span class="math inline">\(x_{mn,i}\)</span> be an indicator
variable such that <span class="math inline">\(x_{mn,i} = 1\)</span> if
allele <span class="math inline">\(m\)</span> from individual <span
class="math inline">\(n\)</span> is of type <span
class="math inline">\(i\)</span> and is 0 otherwise. Clearly, the sample
frequency <span class="math inline">\(\hat p_i =
\frac{1}{2N}\sum_{m=1}^2\sum_{n=1}^Nx_{mn,i}\)</span>, and <span
class="math inline">\(E(\hat p_i) =
p_i\)</span>, <span class="math inline">\(i=1\dots A\)</span>. Assuming
that alleles are sampled independently from the population <span
class="math display">\[\begin{aligned}
E(x^2_{mn,i}) &amp;=&amp; p_i \\
E(x_{mn,i}x_{mn&#39;,i}) = E(x_{mn,i}x_{m&#39;n&#39;,i}) &amp;=&amp;
p_i^2 + \sigma_{x_{mn,i}x_{m&#39;n&#39;,i}} \\
&amp;=&amp; p_i^2 + p_i(1-p_i)\theta
\end{aligned}\]</span> where <span
class="math inline">\(\sigma_{x_{mn,i}x_{m&#39;n&#39;,i}}\)</span> is
the intraclass covariance for the indicator variables and <span
class="math display">\[\theta = \frac{\sigma^2_{p_i}}{p_i(1-p_i)}
\label{eq:theta-def}\]</span> is the scaled among population variance in
allele frequency in the populations from which this population was
sampled. Using (<a href="#eq:theta-def" data-reference-type="ref"
data-reference="eq:theta-def">[eq:theta-def]</a>) we find after some
algebra <span class="math display">\[\sigma^2_{\hat p_i} =
p_i(1-p_i)\theta +
\frac{p_i(1-p_i)(1-\theta)}{2N} \quad .\]</span> The hat on <span
class="math inline">\(\sigma^2_{\hat p_i}\)</span> indicates the
<span><em>sample</em></span> variance of allele frequencies among
popluations. A natural estimate for <span
class="math inline">\(\theta\)</span> emerges using the method of
moments when an analysis of variance is applied to indicator variables
derived from samples representing more than one population.</p>
<h2 class="unnumbered" id="applying-g_st-and-theta">Applying <span
class="math inline">\(G_{st}\)</span> and <span
class="math inline">\(\theta\)</span></h2>
<p>If we return to the data that motivated this discussion, the results
in Table <a href="#table:fst-comparison" data-reference-type="ref"
data-reference="table:fst-comparison">2</a> show what we get from
analyses of the <span class="math inline">\(GOT-1\)</span> data from
<span><em>Isotoma petraea</em></span> (Table <a href="#table:isotoma"
data-reference-type="ref" data-reference="table:isotoma">1</a>).</p>
<div class="center">
<div id="table:fst-comparison">
<table>
<caption>Comparison of Wright’s <span
class="math inline">\(F\)</span>-statistics when ignoring sampling
effects with Nei’s <span class="math inline">\(G_{ST}\)</span> and Weir
and Cockerham’s <span class="math inline">\(\theta\)</span>.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;"><span
class="math inline">\(F_{is}\)</span></th>
<th style="text-align: center;"><span
class="math inline">\(F_{st}\)</span></th>
<th style="text-align: center;"><span
class="math inline">\(F_{it}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Direct</td>
<td style="text-align: center;">0.1372</td>
<td style="text-align: center;">0.2143</td>
<td style="text-align: center;">0.3221</td>
</tr>
<tr class="even">
<td style="text-align: center;">Nei</td>
<td style="text-align: center;">0.3092</td>
<td style="text-align: center;">0.2395</td>
<td style="text-align: center;">0.4746</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Weir &amp; Cockerham</td>
<td style="text-align: center;">0.5398</td>
<td style="text-align: center;">0.0387</td>
<td style="text-align: center;">0.5577</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>But first a note on how you’ll see statistics like this reported in
the literature. It can get a little confusing, because of the different
symbols that are used. Sometimes you’ll see <span
class="math inline">\(F_{is}\)</span>, <span
class="math inline">\(F_{st}\)</span>, and <span
class="math inline">\(F_{it}\)</span>. Sometimes you’ll see <span
class="math inline">\(f\)</span>, <span
class="math inline">\(\theta\)</span>, and <span
class="math inline">\(F\)</span>. And it will seem as if they’re
referring to similar things. That’s because they are. They’re really
just different symbols for the same thing (see Table <a
href="#table:fst-theta" data-reference-type="ref"
data-reference="table:fst-theta">3</a>).</p>
<div class="center">
<div id="table:fst-theta">
<table>
<caption>Equivalent notations often encountered in descriptions of
population genetic structure.</caption>
<tbody>
<tr class="odd">
<td colspan="2" style="text-align: center;">Notation</td>
</tr>
<tr class="even">
<td style="text-align: center;">Wright</td>
<td style="text-align: center;">Weir &amp; Cockerham</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span
class="math inline">\(F_{it}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(F\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span
class="math inline">\(F_{is}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(f\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span
class="math inline">\(F_{st}\)</span></td>
<td style="text-align: center;"><span
class="math inline">\(\theta\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Strictly speaking the symbols in Table <a href="#table:fst-theta"
data-reference-type="ref" data-reference="table:fst-theta">3</a> are the
<span><em>parameters</em></span>, i.e., values in the population that we
try to estimate. We should put hats over any values estimated from data
to indicate that they are estimates of the parameters, not the
parameters themselves. But we’re usually a bit sloppy, and everyone
knows that we’re presenting estimates, so we usually leave off the
hats.</p>
<h1 class="unnumbered" id="an-example-from-wright">An example from
Wright</h1>
<p>Hierarchical analysis of variation in the frequency of the Standard
chromosome arrangement of <span><em>Drosophila pseudoobscura</em></span>
in the western United States (data from <span class="citation"
data-cites="Dobzhansky-Epling-1944"></span>, analysis from <span
class="citation" data-cites="Wright-1978"></span>). Wright uses his
rather peculiar method of accounting for sampling error. I haven’t gone
back to the original data and used a more modern method of analysis.<a
href="#fn30" class="footnote-ref" id="fnref30"
role="doc-noteref"><sup>30</sup></a></p>
<p>66 populations (demes) studied. Demes are grouped into eight regions.
The regions are grouped into four primary subdivisions.</p>
<h2 class="unnumbered" id="results">Results</h2>
<div class="center">
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes within individuals
relative to regions (<span class="math inline">\(F_{IR}\)</span>):</td>
<td style="text-align: center;">0.0444</td>
</tr>
<tr class="even">
<td style="text-align: left;">Correlation of gametes within regions
relative to subdivisions (<span
class="math inline">\(F_{RS}\)</span>):</td>
<td style="text-align: center;">0.0373</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes within subdivisions
relative to total (<span class="math inline">\(F_{ST}\)</span>):</td>
<td style="text-align: center;">0.1478</td>
</tr>
<tr class="even">
<td style="text-align: left;">Correlation of gametes in sample (<span
class="math inline">\(F_{IT}\)</span>):</td>
<td style="text-align: center;">0.2160</td>
</tr>
</tbody>
</table>
</div>
<p><span class="math display">\[1 - F_{IT} = (1 - F_{IR})(1 - F_{RS})(1
- F_{ST})\]</span></p>
<h2 class="unnumbered" id="interpretation">Interpretation</h2>
<p>There is relatively little inbreeding within regions (<span
class="math inline">\(F_{IR}\)</span> = 0.04) and relatively little
genetic differentiation among regions within subdivisions (<span
class="math inline">\(F_{RS} = 0.04\)</span>). There is, however,
substantial genetic differentiation among the subdivisions (<span
class="math inline">\(F_{ST} = 0.15\)</span>).</p>
<p>Thus, an explanation for the chromosomal diversity that predicted
great local differentiation and little or no differentiation at a large
scale would be inconsistent with these observations.</p>
<h1 class="unnumbered" id="reichs-f-statistics">Reich’s <span
class="math inline">\(f\)</span>-statistics</h1>
<p>No, that heading isn’t a typo. I’ve described Wright’s <span
class="math inline">\(F\)</span>-statistics to you, but there are some
other <span class="math inline">\(f\)</span>-statistics you may
encounter and should know about.<a href="#fn31" class="footnote-ref"
id="fnref31" role="doc-noteref"><sup>31</sup></a> The <span
class="math inline">\(f\)</span>-statistics I’ll describe briefly now
were introduced by Reich and colleagues <span class="citation"
data-cites="Reich-etal-2009"></span> in the context of estimating the
populaton history and admixture of human populations on the Indian
subcontinent.<a href="#fn32" class="footnote-ref" id="fnref32"
role="doc-noteref"><sup>32</sup></a> If you read the paper, you won’t
find the definitions in the main text. They’re in Supplement 1.</p>
<p>Reich’s <span class="math inline">\(f\)</span>-statistics are defined
only for markers that have two alleles, like SNP loci. I’m going to use
notation that’s a bit different from that in <span class="citation"
data-cites="Reich-etal-2009"></span>, but it will match more closely
what we’ve been using here, and it should be easier to follow. Let <span
class="math inline">\(m_k\)</span> be the number of 0 alleles in the
sample from population <span class="math inline">\(k\)</span> and let
<span class="math inline">\(m_k\)</span> be the number of 1 alleles in
the sample from population <span class="math inline">\(k\)</span>. <span
class="math inline">\(p_k = n_k/(n_k + m_k)\)</span> is both an unbiased
and a maximum-llikelihood estimate of <span
class="math inline">\(p_k\)</span>. Let’s define <span
class="math display">\[f_4(1,2,3,4) = (p_1 - p_2)(p_3 -  p_4) \quad
.\]</span> If you stare at that a bit,<a href="#fn33"
class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a>
you may recognize that <span class="math inline">\(f_4\)</span> looks
like a correlation coefficient. In fact, as Reich et al. point out, if
the true population phylogeny looks like the one in Figure <a
href="#fig:f4-phylogeny" data-reference-type="ref"
data-reference="fig:f4-phylogeny">1</a>, then the expected value of
<span class="math inline">\(f_4\)</span> is 0. Looking at the figure you
can see that populations 1 and 2 have a common history that is
independent of populations 3 and 4 (and vice versa). As a result, if you
calculate <span class="math inline">\(f_4\)</span> statistics from a
large number of loci, you can see whether the relationship among four
populations is consistent with the phylogeny in Figure <a
href="#fig:f4-phylogeny" data-reference-type="ref"
data-reference="fig:f4-phylogeny">1</a>.</p>
<figure id="fig:f4-phylogeny">
<div class="center">
<img src="f4-phylogeny.png" style="width:15cm" />
</div>
<figcaption>Hypothetical phylogeny for four populations. If you’re
wondering why it’s upside down, I warned you. Population geneticists
look at the world backward from other people. It’s conventional to draw
phylogenies this way in population genetics, probably because, being
geneticists, population geneticists tend to think of them as
pedigrees.</figcaption>
</figure>
<p>We can also define <span class="math display">\[f_3(1,2,3) = (p_1 -
p_2)(p_1 - p_3) - \frac{p_1(1 - p_1)}{n_1} \quad ,\]</span> where <span
class="math inline">\(n_1\)</span> is the sample size in population 1.
The extra term, <span class="math inline">\(\frac{p_1(1 -
p_1)}{n_1}\)</span> makes <span class="math inline">\(f_3\)</span> an
unbiased estimator. <span class="math inline">\(f_3\)</span> measures
how much common history <span class="math inline">\(p_2\)</span> and
<span class="math inline">\(p_3\)</span> share that is independent of
<span class="math inline">\(p_1\)</span>. If the true population
phylogeny looks like the one in Figure <a href="#fig:f3-phylogeny"
data-reference-type="ref" data-reference="fig:f3-phylogeny">2</a>, then
<span class="math display">\[\begin{aligned}
  \mbox{E}\left(f_3(1,2,3)\right) &amp;&gt;&amp;
\mbox{E}\left(f_3(2,1,3)\right) \\
  \mbox{E}\left(f_3(1,2,3)\right) &amp;&gt;&amp;
\mbox{E}\left(f_3(3,1,2)\right)
  \quad . \\
\end{aligned}\]</span> Finally we can define <span
class="math display">\[f_2(1,2) = (p_1 - p_2)^2 - \frac{p_1(1 -
p_1)}{n_1} - \frac{p_1(1 -
    p_1)}{n_1} \quad ,\]</span> which gives an unbiased estimate of
squared allele frequency differences between populations, analogous to
pairwise <span class="math inline">\(F\)</span>-statistics.</p>
<figure id="fig:f3-phylogeny">
<div class="center">
<img src="f3-phylogeny.png" style="width:15cm" />
</div>
<figcaption>Hypothetical phylogeny for three populations.</figcaption>
</figure>
<h1 class="unnumbered" id="creative-commons-license">Creative Commons
License</h1>
<p>These notes are licensed under the Creative Commons Attribution
License. To view a copy of this license, visit or send a letter to
Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305,
USA.</p>
<aside id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Those of you who’ve been in EEB for a while will know
that these are probably different species, but humor me, and forget that
you know that.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>If we ignore sampling error.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For the time being, I’m going to assume that we know the
allele frequencies without error, i.e., that we didn’t have to estimate
them from data. We’ll deal with real life, i.e., how we can detect the
Wahlund effect when we have to <span><em>estimate</em></span> allele
freqeuncies from data, a little later.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>We’d get the same result by relaxing this assumption,
but the algebra gets messier, so why bother?<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>For example, if we combine samples from different years
or across age classes of long-lived organisms, we may see a deficienty
of heterozygotes in the sample purely as a result of allele frequency
differences across years. Remember that I told you one of the
assumptions underlying derivation of the Hardy-Weinberg principle is
that generations are non-overlapping? This is why.<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>If you’re curious about this, feel free to ask, but I’ll
have to dig out my copy of Li <span class="citation"
data-cites="Li-1976"></span> to answer. I don’t carry those details
around in my head.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>And this is what we predicted when we started.<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>The reason for the subscript will become apparent later.
It’s also <span><em>very</em></span> important to notice that I’m
defining <span class="math inline">\(F_{ST}\)</span> here in terms of
the population parameters <span class="math inline">\(p\)</span> and
<span class="math inline">\(\mbox{Var}(p)\)</span>. Again, we’ll return
to the problem of how to <span> <em>estimate</em></span> <span
class="math inline">\(F_{ST}\)</span> from data a little later.<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>To be precise, it is a form of positive assortative
mating in which the choice of mates is based on geographical
proximity.<a href="#fnref9" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>I say “one way”, because there are several other ways
to talk about <span class="math inline">\(F_{st}\)</span>, too. But we
won’t talk about them until later.<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>At least it’s easy once you’ve been shown how.<a
href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Please remember that we’re assuming we know those
frequencies exactly. In real applications, of course, we’ll <span>
<em>estimate</em></span> those frequencies from data, so we’ll have to
account for sampling error when we actually try to estimate these
things. If you’re getting the impression that I think the distinction
between allele frequencies as <span><em>parameters</em></span>, i.e.,
the real allele frequency in the population , and allele frequencies as
<span> <em>estimates</em></span>, i.e., the sample frequencies from
which we hope to estimate the paramters, is really important, you’re
getting the right impression.<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Are you beginning to see how peculiar I am? Do you know
anyone else who gets a kick out of playing around with formulas and
equations.<a href="#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>It takes a fair amount of algebra to show that this
definition of <span class="math inline">\(F_{st}\)</span> is equivalent
to the one I showed you before, so you’ll just have to take my word for
it.<a href="#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Probably because he published in English and
Mal<span>é</span>cot published in French.<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>The Hardy-Weinberg proportions should probably be
referred to as the Hardy-Weinberg-Castle proportions too, since Castle
pointed out the same principle. For some reason, though, his
demonstration didn’t have the impact that Hardy’s and Weinberg’s did. So
we generally talk about the Hardy-Weinberg principle.<a href="#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>And as we’ll soon see, I’m not too crazy about one of
these three. To my mind, there are really only two approaches that
anyone should consider, and those two approaches are really just
variants of the same basic idea.<a href="#fnref17" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>This is, as you have probably already guessed, my
personal favorite. We don’t have time to discuss it in lecture, but if
you’re interested, ask me about it. I should also tell you that Gregory
Owens pointed out on Twitter that arguments about genetic
differentiation can get a little heated (<a
href="https://twitter.com/Greg_Owens/status/1582104811629346817"
class="uri">https://twitter.com/Greg_Owens/status/1582104811629346817</a>).
They may not turn into an actual fistfight, but there have been some
pretty extreme statements made.</p>
<div class="center">
<p><img src="Fst-fight.png" style="height:2.5cm" alt="image" /></p>
</div>
<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></li>
<li id="fn19"><p>See <span class="citation"
data-cites="Weir-1996"></span> for details.<a href="#fnref19"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><span class="math inline">\(\mbox{P}(k|p,N) = {N
\choose k}p^k(1-p)^{N-k}\)</span>. The algebra in getting from the first
line to the second is a little complicated, but feel free to ask me
about it if you’re intersted.<a href="#fnref20" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>Notice that I’m using a hat here to refer to a
statistical estimate. Remember when I told you I’d be using hats for a
couple of different purposes? Well, this is the second one.<a
href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p>If you’re wondering how I got from the second equation
for <span class="math inline">\(\hat H\)</span> to the last one, ask me
about it or read the gory details section that follows. TAMO is short
for “Then a miracle occurs.” You’ll see that acronym repeatedly this
semester.<a href="#fnref22" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p>Skip this part unless you are <span><em>really,
really</em></span> interested in how I got from the second equation to
the third equation in the last paragraph. This is more likely to confuse
you than help unless you know that the variance of a binomial sample is
<span class="math inline">\(np(1-p)\)</span> and that <span
class="math inline">\(E(k^2) = \hbox{Var}(p) +
p^2\)</span>.<a href="#fnref23" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>There’s actually a third source of error that we’ll get
to in a moment. The populations we’re sampling from are the product of
an evolutionary process, and since the populations aren’t of infinite
size, drift has played a role in determining allele frequencies in them.
As a result, if we were to go back in time and re-run the evolutionary
process, we’d end up with a different set of real allele frequency
differences. We’ll talk about this more in just a moment when we get to
Weir and Cockerham’s statistics.<a href="#fnref24" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p><span><code>Popgene</code></span> estimates <span
class="math inline">\(G_{st}\)</span>, but I don’t think it’s been
updated since 2000. <span><code>FSTAT</code></span> also estimates gene
diversities, but the most recent version is from 2002.<a href="#fnref25"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p>There’s a reason for this that we’ll get to in a
moment. It’s alluded to in the footnote before the last one.<a
href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p>It is also one big reason why most people use Weir and
Cockerham’s <span class="math inline">\(\theta\)</span>. There’s readily
available software that calculates it for you.<a href="#fnref27"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p>We also talk a bit more about how <span
class="math inline">\(F\)</span>-statistics can be used. If you just
can’t get enough of this, I suggest you take a look at Verity and
Nichols <span class="citation" data-cites="Verity-Nichols-2014"></span>.
They provide a really solid analysis of <span
class="math inline">\(F_{ST}\)</span>, <span
class="math inline">\(G_{ST}\)</span>, and some related statistics.<a
href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p>This is even worse than the last time. I include it for
completeness only. I really don’t expect anyone (unless they happen to
be a statistician) to be able to understand these details. I wouldn’t
recommend spending time trying to understand this unless you really,
really want to understand the mathematical underpinnings of Weir and
Cockerham’s statistics. I’ve explained the fundamental principles in the
text. This is just a lot of algebra, which admittedly entertains some of
us who have a perverse fascination with these things.<a href="#fnref29"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p>Sounds like it might be a good project, doesn’t it?
We’ll see.<a href="#fnref30" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p>Remember when I told you that population geneticists
commonly use the same symbol or letter to refer to different things.
This is another example of that. At least in this case one uses an
uppercase <span class="math inline">\(F\)</span> and the other uses a
lowercase <span class="math inline">\(f\)</span>.<a href="#fnref31"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p>The software that makes <span
class="math inline">\(f\)</span>-statistics useful in admixture
analysis, <span><code>AdmixTools</code></span> (<a
href="https://github.com/DReichLab/AdmixTools"
class="uri">https://github.com/DReichLab/AdmixTools</a>), requires that
you have a C compiler, that you know how to use make to compile
executables from C source code, and that you know how to install the
libraries on which AdmixTools depends. Because of all of those
requirements, we won’t be using <span><code>AdmixTools</code></span> in
this course. If you have data where it might be useful, I encourage you
to explore it and to explore the <span><code>R</code></span> package
<span><code>admixr</code></span>, which provides a convenient interface
for it.<a href="#fnref32" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p>And if you remember how a correlation coefficient is
defined.<a href="#fnref33" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</aside>
</body>
</html>
