<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Analyzing the genetic structure of populations</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="pandoc.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Analyzing the genetic structure of populations</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#a-numerical-example">A numerical example</a></li>
<li><a href="#the-algebraic-development">The algebraic development</a></li>
<li><a href="#wrights-f-statistics">Wright’s <span class="math inline">\(F\)</span>-statistics</a></li>
<li><a href="#estimating-f-statistics">Estimating <span class="math inline">\(F\)</span>-statistics</a></li>
<li><a href="#an-example-from-isotoma-petraea">An example from <span><em>Isotoma petraea</em></span></a>
<ul>
<li><a href="#summary">Summary</a></li>
</ul></li>
<li><a href="#statistical-expectation-and-unbiased-estimates">Statistical expectation and unbiased estimates</a>
<ul>
<li><a href="#the-gory-details">The gory details</a></li>
</ul></li>
<li><a href="#corrections-for-sampling-error">Corrections for sampling error</a>
<ul>
<li><a href="#neis-g_st">Nei’s <span class="math inline">\(G_{st}\)</span></a></li>
<li><a href="#weir-and-cockerhams-theta">Weir and Cockerham’s <span class="math inline">\(\theta\)</span></a>
<ul>
<li><a href="#even-more-gory-details">Even more gory details</a></li>
</ul></li>
<li><a href="#applying-g_st-and-theta">Applying <span class="math inline">\(G_{st}\)</span> and <span class="math inline">\(\theta\)</span></a></li>
</ul></li>
<li><a href="#an-example-from-wright">An example from Wright</a>
<ul>
<li><a href="#results">Results</a></li>
<li><a href="#interpretation">Interpretation</a></li>
</ul></li>
<li><a href="#creative-commons-license">Creative Commons License</a></li>
</ul>
</nav>
<h1 class="unnumbered" id="introduction">Introduction</h1>
<p>So far we’ve focused on inbreeding as one important way that populations may fail to mate at random, but there’s another way in which virtually all populations and species fail to mate at random. Individuals tend to mate with those that are nearby. Even within a fairly small area, phenomena like nearest neighbor pollination in flowering plants or home-site fidelity in animals can cause mates to be selected in a geographically non-random way. What are the population genetic consequences of this form of non-random mating?</p>
<p>Well, if you think about it a little, you can probably figure it out. Since individuals that occur close to one another tend to be more genetically similar than those that occur far apart, the impacts of local mating will mimic those of inbreeding within a single, well-mixed population.</p>
<h1 class="unnumbered" id="a-numerical-example">A numerical example</h1>
<p>For example, suppose we have two subpopulations of green lacewings, one of which occurs in forests the other of which occurs in adjacent meadows.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Suppose further that within each subpopulation mating occurs completely at random, but that there is no mating between forest and meadow individuals. Suppose we’ve determined allele frequencies in each population at a locus coding for phosphoglucoisomerase (<span class="math inline">\(PGI\)</span>), which conveniently has only two alleles. The frequency of <span class="math inline">\(A_1\)</span> in the forest is 0.4 and in the meadow in 0.7. We can easily calculate the expected genotype frequencies within each population, namely</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Forest</td>
<td style="text-align: right;">0.16</td>
<td style="text-align: right;">0.48</td>
<td style="text-align: right;">0.36</td>
</tr>
<tr class="even">
<td style="text-align: left;">Meadow</td>
<td style="text-align: right;">0.49</td>
<td style="text-align: right;">0.42</td>
<td style="text-align: right;">0.09</td>
</tr>
</tbody>
</table>
<p>Suppose, however, we were to consider a combined population consisting of 100 individuals from the forest subpopulation and 100 individuals from the meadow subpopulation. Then we’d get the following:<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">From forest</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">48</td>
<td style="text-align: right;">36</td>
</tr>
<tr class="even">
<td style="text-align: left;">From meadow</td>
<td style="text-align: right;">49</td>
<td style="text-align: right;">42</td>
<td style="text-align: right;">9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Total</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">90</td>
<td style="text-align: right;">45</td>
</tr>
</tbody>
</table>
<p>So the frequency of <span class="math inline">\(A_1\)</span> is <span class="math inline">\((2(65) + 90)/(2(65 + 90 + 45)) =
0.55\)</span>. Notice that this is just the average allele frequency in the two subpopulations, i.e., <span class="math inline">\((0.4 + 0.7)/2\)</span>. Since each subpopulation has genotypes in Hardy-Weinberg proportions, you might expect the combined population to have genotypes in Hardy-Weinberg proportions, but if you did you’d be wrong. Just look.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Expected (from <span class="math inline">\(p=0.55\)</span>)</td>
<td style="text-align: right;">(0.3025)200</td>
<td style="text-align: right;">(0.4950)200</td>
<td style="text-align: right;">(0.2025)200</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: right;">60.5</td>
<td style="text-align: right;">99.0</td>
<td style="text-align: right;">40.5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Observed (from table above)</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">90</td>
<td style="text-align: right;">45</td>
</tr>
</tbody>
</table>
<p>The expected and observed don’t match, even though there is random mating within both subpopulations. They don’t match because there isn’t random mating <span><em>in the combined population</em></span>, only within each subpopulation. Forest lacewings choose mates at random from other forest lacewings, but they never mate with a meadow lacewing (and <span> <em>vice versa</em></span>). Our sample includes two populations that don’t mix. As a result, heterozygotes in our combined sample are less frequent (<span class="math inline">\(0.45\)</span> vs <span class="math inline">\(0.495\)</span>) than we’d expect if the population were well mixed with an allelel frequency of <span class="math inline">\(0.55\)</span>. This is an example of what’s known as the <span><em>Wahlund effect</em></span> <span class="citation" data-cites="Wahlund-1928"></span>.</p>
<h1 class="unnumbered" id="the-algebraic-development">The algebraic development</h1>
<p>Even though you’ve only known me for a couple of weeks now, you should know me well enough to know that I’m not going to be satisfied with a numerical example. You should know that I now feel the need to do some algebra to describe this situation a little more generally.</p>
<p>Suppose we know allele frequencies in <span class="math inline">\(k\)</span> subpopulations.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Let <span class="math inline">\(p_i\)</span> be the frequency of <span class="math inline">\(A_1\)</span> in the <span class="math inline">\(i\)</span>th subpopulation. Then if we assume that all subpopulations contribute equally to combined population,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> we can calculate expected and observed genotype frequencies the way we did above:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Expected</td>
<td style="text-align: right;"><span class="math inline">\(\bar p^2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(2\bar p\bar q\)</span></td>
<td style="text-align: right;"><span class="math inline">\(\bar q^2\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Observed</td>
<td style="text-align: right;"><span class="math inline">\(\frac{1}{k}\sum p_i^2\)</span></td>
<td style="text-align: right;"><span class="math inline">\(\frac{1}{k}\sum 2p_iq_i\)</span></td>
<td style="text-align: right;"><span class="math inline">\(\frac{1}{k}\sum q_i^2\)</span></td>
</tr>
</tbody>
</table>
<p>where <span class="math inline">\(\bar p = \sum p_i/k\)</span> and <span class="math inline">\(\bar q = 1 - \bar p\)</span> are the average allele frequencies in the combined sample. Now <span class="math display">\[\begin{aligned}
\frac{1}{k}\sum p_i^2 &amp;=&amp; \frac{1}{k}\sum (p_i - \bar p + \bar p)^2 \\
&amp;=&amp; \frac{1}{k}\sum \left((p_i - \bar p)^2 + 2\bar p(p_i - \bar p)
                            + \bar p^2\right) \\
             &amp;=&amp; \frac{1}{k}\sum (p_i - \bar p)^2 + \bar p^2 \\
             &amp;=&amp; \hbox{Var}(p) + \bar p^2 \label{eq:p2}\end{aligned}\]</span> Similarly, <span class="math display">\[\begin{aligned}
\frac{1}{k}\sum 2p_iq_i &amp;=&amp; 2\bar p\bar q - 2\hbox{Var}(p) \label{eq:2pq} \\
\frac{1}{k}\sum q_i^2   &amp;=&amp; \bar q^2 + \hbox{Var}(p) \label{eq:q2}\end{aligned}\]</span></p>
<p>Since <span class="math inline">\(\hbox{Var}(p) \ge 0\)</span> by definition, with equality holding only when all subpopulations have the same allele frequency, we can conclude that</p>
<ul>
<li><p>Homozygotes will be more frequent and heterozygotes will be less frequent than expected based on the allele frequency in the combined population.</p></li>
<li><p>The magnitude of the departure from expectations is directly related to the magnitude of the variance in allele frequencies across populations, <span class="math inline">\(\hbox{Var}(p)\)</span>.</p></li>
<li><p>The effect will apply to <span><em>any</em></span> mixing of samples in which the subpopulations combined have different allele frequencies.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p></li>
<li><p>The same general phenomenon will occur if there are multiple alleles at a locus, although it is possible for one or a few heterozygotes to be <span><em>more</em></span> frequent than expected if there is positive covariance in the constituent allele frequencies across populations.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p></li>
<li><p>The effect is analogous to inbreeding. Homozygotes are more frequent and heterozygotes are less frequent than expected.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p></li>
</ul>
<p>To return to our earlier numerical example:</p>
<p><span class="math display">\[\begin{aligned}
\hbox{Var}(p) &amp;=&amp; \left((0.4 - 0.55)^2 + (0.7 - 0.55)^2\right)/2 \\
              &amp;=&amp; 0.0225\end{aligned}\]</span></p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Expected</th>
<th style="text-align: center;"></th>
<th style="text-align: right;"></th>
<th style="text-align: center;"></th>
<th style="text-align: right;">Observed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(A_1A_1\)</span></td>
<td style="text-align: right;">0.3025</td>
<td style="text-align: center;">+</td>
<td style="text-align: right;">0.0225</td>
<td style="text-align: center;">=</td>
<td style="text-align: right;">0.3250</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(A_1A_2\)</span></td>
<td style="text-align: right;">0.4950</td>
<td style="text-align: center;">-</td>
<td style="text-align: right;">2(0.0225)</td>
<td style="text-align: center;">=</td>
<td style="text-align: right;">0.4500</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(A_2A_2\)</span></td>
<td style="text-align: right;">0.2025</td>
<td style="text-align: center;">+</td>
<td style="text-align: right;">0.0225</td>
<td style="text-align: center;">=</td>
<td style="text-align: right;">0.2250</td>
</tr>
</tbody>
</table>
<h1 class="unnumbered" id="wrights-f-statistics">Wright’s <span class="math inline">\(F\)</span>-statistics</h1>
<p>One limitation of the way I’ve described things so far is that <span class="math inline">\(\hbox{Var}(p)\)</span> doesn’t provide a convenient way to compare population structure from different samples. <span class="math inline">\(\hbox{Var}(p)\)</span> can be much larger if both alleles are about equally common in the whole sample than if one occurs at a mean frequency of 0.99 and the other at a frequency of 0.01. Moreover, if you stare at equations (<a href="#eq:p2" data-reference-type="ref" data-reference="eq:p2">[eq:p2]</a>)–(<a href="#eq:q2" data-reference-type="ref" data-reference="eq:q2">[eq:q2]</a>) for a while, you begin to realize that they look a lot like some equations we’ve already encountered. Namely, if we were to define <span class="math inline">\(F_{st}\)</span><a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> as <span class="math inline">\(\mbox{Var}(p)/\bar p\bar q\)</span>, then we could rewrite equations (<a href="#eq:p2" data-reference-type="ref" data-reference="eq:p2">[eq:p2]</a>)–(<a href="#eq:q2" data-reference-type="ref" data-reference="eq:q2">[eq:q2]</a>) as <span class="math display">\[\begin{aligned}
\frac{1}{k}\sum p_i^2 &amp;=&amp; \bar p^2 + F_{st}\bar p \bar q \label{eq:p2-f} \\
\frac{1}{k}\sum 2p_iq_i &amp;=&amp; 2\bar p\bar q(1 - F_{st}) \label{eq:2pq-f} \\
\frac{1}{k}\sum q_i^2   &amp;=&amp; \bar q^2 + F_{st}\bar p \bar q \label{eq:q2-f}\end{aligned}\]</span> And it’s not even completely artificial to define <span class="math inline">\(F_{st}\)</span> the way I did. After all, the effect of geographic structure is to cause matings to occur among genetically similar individuals. It’s rather like inbreeding.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> Moreover, the extent to which this local mating matters depends on the extent to which populations differ from one another. It turns out that <span class="math inline">\(\bar p\bar q\)</span> is the maximum allele frequency variance possible, given the observed mean frequency. So one way of thinking about <span class="math inline">\(F_{st}\)</span> is that it measures the amount of allele frequency variance in a sample relative to the maximum possible.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>There may, of course, be inbreeding within populations, too. But it’s easy to incorporate this into the framework, too.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> Let <span class="math inline">\(H_i\)</span> be the actual heterozygosity in individuals within subpopulations, <span class="math inline">\(H_s\)</span> be the expected heterozygosity within subpopulations assuming Hardy-Weinberg within populations, and <span class="math inline">\(H_t\)</span> be the expected heterozygosity in the combined population assuming Hardy-Weinberg over the whole sample.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> Then thinking of <span class="math inline">\(f\)</span> as a measure of departure from Hardy-Weinberg and assuming that all populations depart from Hardy-Weinberg to the same degree, i.e., that they all have the same <span class="math inline">\(f\)</span>, we can define <span class="math display">\[F_{it} = 1 - \frac{H_i}{H_t} \quad .\]</span> <span class="math inline">\(F_{it}\)</span> is the overall departure from Hardy-Weinberg in the entire sample. Let’s fiddle with <span class="math inline">\(F_{ST}\)</span> a bit.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> <span class="math display">\[\begin{aligned}
1 - F_{it} &amp;=&amp; \frac{H_i}{H_t} \\
           &amp;=&amp; \left(\frac{H_i}{H_s}\right)\left(\frac{H_s}{H_t}\right) \\
           &amp;=&amp; (1 - F_{is})(1 - F_{st}) \quad ,\end{aligned}\]</span> where <span class="math inline">\(F_{is}\)</span> is the inbreeding coefficient within populations, i.e., <span class="math inline">\(f\)</span>, and <span class="math inline">\(F_{st}\)</span> has the same definition as before.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> <span class="math inline">\(H_t\)</span> is often referred to as the genetic diversity in a population. So another way of thinking about <span class="math inline">\(F_{st} =
(H_t - H_s)/H_t\)</span> is that it’s the proportion of the diversity in the sample that’s due to allele frequency differences among populations.</p>
<h1 class="unnumbered" id="estimating-f-statistics">Estimating <span class="math inline">\(F\)</span>-statistics</h1>
<p>We’ve now seen the principles underlying Wright’s <span class="math inline">\(F\)</span>-statistics. I should point out that Gustave Mal<span>é</span>cot developed very similar ideas at about the same time as Wright, but since Wright’s notation stuck,<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> population geneticists generally refer to statistics like those we’ve discussed as Wright’s <span class="math inline">\(F\)</span>-statistics.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
<p>Neither Wright nor Mal<span>é</span>cot worried too much about the problem of estimating <span class="math inline">\(F\)</span>-statistics from data. Both realized that any inferences about population structure are based on a sample and that the characteristics of the sample may differ from those of the population from which it was drawn, but neither developed any explicit way of dealing with those differences. Wright develops some very <span><em>ad hoc</em></span> approaches in his book <span class="citation" data-cites="Wright69"></span>, but they have been forgotten, which is good because they aren’t satisfactory and they shouldn’t be used. There are now three reasonable approaches available:<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
<ol>
<li><p>Nei’s <span class="math inline">\(G\)</span>-statistics,</p></li>
<li><p>Weir and Cockerham’s <span class="math inline">\(\theta\)</span>-statistics, and</p></li>
<li><p>A Bayesian analog of <span class="math inline">\(\theta\)</span>.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p></li>
</ol>
<h1 class="unnumbered" id="an-example-from-isotoma-petraea">An example from <span><em>Isotoma petraea</em></span></h1>
<p>To make the differences in implementation and calculation clear, I’m going to use data from 12 populations of <span><em>Isotoma petraea</em></span> in southwestern Australia surveyed for genotype at <span> <em>GOT</em></span>–1 <span class="citation" data-cites="James-etal-1983"></span> as an example throughout these discussions (Table <a href="#table:isotoma" data-reference-type="ref" data-reference="table:isotoma">1</a>).</p>
<div id="table:isotoma">
<table>
<caption>Genotype counts at the <span class="math inline">\(GOT-1\)</span> locus in <span><em>Isotoma petraea</em></span> (from <span class="citation" data-cites="James-etal-1983"></span>).</caption>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Population</td>
<td style="text-align: right;"><span class="math inline">\(A_{1}A_{1}\)</span></td>
<td style="text-align: right;"><span class="math inline">\(A_{1}A_{2}\)</span></td>
<td style="text-align: right;"><span class="math inline">\(A_{2}A_{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\hat p\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Yackeyackine Soak</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Gnarlbine Rock</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">0.7750</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Boorabbin</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: center;">0.8000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Bullabulling</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Mt. Caudan</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: center;">Victoria Rock</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">2</td>
<td style="text-align: center;">0.8500</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Yellowdine</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: center;">0.8167</td>
</tr>
<tr class="even">
<td style="text-align: center;">Wargangering</td>
<td style="text-align: right;">29</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">1</td>
<td style="text-align: center;">0.9242</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Wagga Rock</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: center;">“Iron Knob Major”</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Rainy Rocks</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">0.5000</td>
</tr>
<tr class="even">
<td style="text-align: center;">“Rainy Rocks Major”</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: center;">1.0000</td>
</tr>
</tbody>
</table>
</div>
<p>Let’s ignore the sampling problem for a moment and calculate the <span class="math inline">\(F\)</span>-statistics as if we had observed the population allele frequencies without error. They’ll serve as our baseline for comparison. <span class="math display">\[\begin{aligned}
\bar p &amp;=&amp; 0.8888 \\
\hbox{Var}(p) &amp;=&amp; 0.02118 \\
F_{st} &amp;=&amp; 0.2143 \\
\hbox{Individual heterozygosity} &amp;=&amp; (0.0000 + 0.1500 + 0.1000 +
                                      0.0000 + 0.0000 + 0.1667 +
                                      0.1000 \\
                                 &amp;&amp;   + 0.0909 + 0.0000 +
                                      0.0000 + 1.0000 + 0.0000)/12 \\
                           &amp;=&amp; 0.1340 \\
\hbox{Expected heterozygosity} &amp;=&amp; 2(0.8888)(1 - 0.8888) \\
                           &amp;=&amp; 0.1976 \\
F_{it} &amp;=&amp; 1 - \frac{\hbox{Individual heterozygosity}}%
                    {\hbox{Expected heterozygosity}} \\
                  &amp;=&amp; 1 - \frac{0.1340}{0.1976} \\
                  &amp;=&amp; 0.3221 \\
       1 - F_{it} &amp;=&amp; (1 - F_{is})(1 - F_{st}) \\
           F_{is} &amp;=&amp; \frac{F_{it} - F_{st}}{1 - F_{st}} \\
                  &amp;=&amp; \frac{0.3221 - 0.2143}{1 - 0.2143} \\
                  &amp;=&amp; 0.1372\end{aligned}\]</span></p>
<h2 class="unnumbered" id="summary">Summary</h2>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes due to inbreeding within subpopulations (<span class="math inline">\(F_{is}\)</span>):</td>
<td style="text-align: center;">0.1372</td>
</tr>
<tr class="even">
<td style="text-align: left;">Correlation of gametes within subpopulations (<span class="math inline">\(F_{st}\)</span>):</td>
<td style="text-align: center;">0.2143</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes in sample (<span class="math inline">\(F_{it}\)</span>):</td>
<td style="text-align: center;">0.3221</td>
</tr>
</tbody>
</table>
<p>Why do I refer to them as the “correlation of gametes <span class="math inline">\(\dots\)</span>”? There are two reasons:</p>
<ol>
<li><p>That’s the way Wright always referred to and interpreted them.</p></li>
<li><p>We can define indicator variables <span class="math inline">\(x_{ijk} = 1\)</span> if the <span class="math inline">\(i\)</span>th allele in the <span class="math inline">\(jth\)</span> individual of population <span class="math inline">\(k\)</span> is <span class="math inline">\(A_1\)</span> and <span class="math inline">\(x_{ijk} = 0\)</span> if that allele is not <span class="math inline">\(A_1\)</span>. This may seem like a strange thing to do, but the Weir and Cockerham approach to <span class="math inline">\(F\)</span>-statistics described below uses just such an approach. If we do this, then the definitions for <span class="math inline">\(F_{is}\)</span>, <span class="math inline">\(F_{st}\)</span>, and <span class="math inline">\(F_{it}\)</span> follow directly.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p></li>
</ol>
<p>Notice that <span class="math inline">\(F_{is}\)</span> could be negative, i.e., there could be an <span> <em>excess</em></span> of heterozygotes within populations (<span class="math inline">\(F_{is} &lt; 0\)</span>). Notice also that we’re implicitly assuming that the extent of departure from Hardy-Weinberg proportions is the same in all populations. Equivalently, we can regard <span class="math inline">\(F_{is}\)</span> as the <span> <em>average</em></span> departure from Hardy-Weinberg proportions across all populations.</p>
<h1 class="unnumbered" id="statistical-expectation-and-unbiased-estimates">Statistical expectation and unbiased estimates</h1>
<p>So far I’ve assumed that we know the allele frequencies without error, but of course that’s never the case unless we’ve created experimental populations. We are always taking a sample from a population and inferringestimatingallele frequencies from our sample. Similarly, we are <span><em>estimating</em></span> <span class="math inline">\(F_{ST}\)</span> and our estimate of <span class="math inline">\(F_{ST}\)</span> needs to take account of the imprecision in the allele frequency estimates on which it was based. To understand one approach to dealing with this uncertainty I need to introduce two new concepts: <span><em>statistical expectation</em></span> and <span> <em>unbiased estimates</em></span>.</p>
<p>The concept of statistical expectation is actually quite an easy one. It is an arithmetic average, just one calculated from probabilities instead of being calculated from samples. So, for example, let <span class="math inline">\(\mbox{P}(k|p,N)\)</span> be the probability that we find <span class="math inline">\(k\)</span> <span class="math inline">\(A_1\)</span> alleles in our sample of size <span class="math inline">\(N\)</span> given that the allele frequency in the population is <span class="math inline">\(p\)</span>. Then the <span><em>expected number</em></span> of <span class="math inline">\(A_1\)</span> alleles in our sample is just <span class="math display">\[\begin{aligned}
\mbox{E}(k) &amp;=&amp; \sum_{k=0}^n k \mbox{P}(k|p,N) \\
     &amp;=&amp; n p \quad  \\\end{aligned}\]</span> where <span class="math inline">\(n\)</span> is the total number of alleles in our sample.<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a></p>
<p>Now consider the expected value of our sample estimate of the population allele frequency, <span class="math inline">\(\hat p = k/n\)</span>, where <span class="math inline">\(k\)</span> now refers to the number of <span class="math inline">\(A_1\)</span> alleles we actually found. <span class="math display">\[\begin{aligned}
\mbox{E}(\hat p) &amp;=&amp; \mbox{E}\left(\sum_{k=1}^n (k/n)\right) \\
          &amp;=&amp; \sum_{k=1}^n (k/n) P(k|p,N) \\
          &amp;=&amp; (1/n)\left(\sum_{k=1}^n k P(k|p,N)\right) \\
          &amp;=&amp; (1/n)(n p) \\
          &amp;=&amp; p \quad . \\\end{aligned}\]</span> Because <span class="math inline">\(\mbox{E}(\hat p) = p\)</span>, <span class="math inline">\(\hat p\)</span> is said to be an <span> <em>unbiased estimate</em></span> of <span class="math inline">\(p\)</span>.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a> When an estimate is unbiased it means that if we were to repeat the sampling experiment an infinite number of times and to take the average of the estimates, the average of those values would be equal to the (unknown) parameter value.</p>
<p>What about estimating the frequency of heterozygotes within a population? The obvious estimator is <span class="math inline">\(\tilde H = 2\hat p (1 - \hat
p)\)</span>. Well, <span class="math display">\[\begin{aligned}
\mbox{E}(\tilde H) &amp;=&amp; \mbox{E}\left(2\hat p (1 - \hat p)\right) \\
     &amp;=&amp; 2\left(\mbox{E}(\hat p) - \mbox{E}({\hat p}^2)\right) \\
     &amp;=&amp; \mbox{TAMO} \\
     &amp;=&amp; ((n-1)/n)2p(1-p) \quad . \\\end{aligned}\]</span> Because <span class="math inline">\(\mbox{E}(\tilde H) \ne 2p(1-p)\)</span>, <span class="math inline">\(\tilde H\)</span> is a <span><em>biased estimate</em></span> of <span class="math inline">\(2p(1-p)\)</span>. If, however, we set <span class="math inline">\(\hat H = (n/(n-1))\tilde H\)</span>, however, <span class="math inline">\(\hat H\)</span> is an unbiased estimator of <span class="math inline">\(2p(1-p)\)</span>.<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a></p>
<p>If you’ve ever wondered why you typically divide the sum of squared deviations about the mean by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span> when estimating the variance of a sample, this is why. Dividing by <span class="math inline">\(n\)</span> gives you a (slightly) biased estimator.</p>
<h2 class="unnumbered" id="the-gory-details">The gory details<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a></h2>
<p>Starting where we left off above: <span class="math display">\[\begin{aligned}
\mbox{E}(\tilde H) &amp;=&amp; 2\left((\mbox{E}\hat p) - \mbox{E}({\hat p}^2)\right) \\
     &amp;=&amp; 2\left(p - \mbox{E}\left((k/n)^2\right)\right) \quad ,\end{aligned}\]</span> where <span class="math inline">\(k\)</span> is the number of <span class="math inline">\(A_1\)</span> alleles in our sample and <span class="math inline">\(n\)</span> is the sample size. <span class="math display">\[\begin{aligned}
\mbox{E}\left((k/n)^2\right) &amp;=&amp; \sum (k/n)^2 \mbox{P}(k|p,N) \\
                      &amp;=&amp; (1/n)^2 \sum k^2 \mbox{P}(k|p,N) \\
                      &amp;=&amp; (1/n)^2 \left(\mbox{Var}(k) + \bar k^2\right) \\
                      &amp;=&amp; (1/n)^2 \left(np(1-p) + n^2p^2\right) \\
                      &amp;=&amp; p(1-p)/n + p^2 \quad .\end{aligned}\]</span> Substituting this back into the equation above yields the following: <span class="math display">\[\begin{aligned}
\mbox{E}(\tilde H) &amp;=&amp; 2\left(p - \left(p(1-p)/n + p^2\right)\right) \\
     &amp;=&amp; 2\left(p(1-p) - p(1-p)/n\right) \\
     &amp;=&amp; \left(1 - 1/n\right)2p(1-p) \\
     &amp;=&amp; ((n-1)/n)2p(1-p) \quad . \\\end{aligned}\]</span></p>
<h1 class="unnumbered" id="corrections-for-sampling-error">Corrections for sampling error</h1>
<p>There are two sources of allele frequency difference among subpopulations in our sample: (1) real differences in the allele frequencies among our sampled subpopulations and (2) differences that arise because allele frequencies in our samples differ from those in the subpopulations from which they were taken.<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a></p>
<h2 class="unnumbered" id="neis-g_st">Nei’s <span class="math inline">\(G_{st}\)</span></h2>
<p>Nei and Chesser <span class="citation" data-cites="Nei-Chesser-1983"></span> described one approach to accounting for sampling error. So far as I’ve been able to determine, there aren’t any currently supported programs<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a> that calculate the bias-corrected versions of <span class="math inline">\(G_{st}\)</span>.<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a> I calculated the results in Table <a href="#table:fst-comparison" data-reference-type="ref" data-reference="table:fst-comparison">2</a> by hand.</p>
<p>The calculations are tedious, which is why you’ll want to find some way of automating the caluclations if you want to do them.<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a> <span class="math display">\[\begin{aligned}
H_{i} &amp;=&amp; 1 - {1 \over N} \sum_{k=1}^{N} \sum_{i=1}^{m} {X_{kii}} \\
H_{s} &amp;=&amp; {\tilde n \over {\tilde n - 1}}
         \left[1 - \sum_{i=1}^{m} {\bar {\hat x_{i}^{2}}}
         - {H_{I} \over {2 \tilde n}}\right] \\
H_{t} &amp;=&amp; 1 - \sum_{i=1}^{m} {\bar x_{i}^{2}} + {H_{S} \over {\tilde n}}
         - {H_{I} \over {2 \tilde n N}}\end{aligned}\]</span> where we have <span class="math inline">\(N\)</span> subpopulations, <span class="math inline">\({\bar {\hat x_{i}^{2}}} = \sum_{k=1}^{N} {x_{ki}^{2}}/N\)</span>, <span class="math inline">\({\bar x_{i}} = \sum_{k=1}^{N} x_{ki}/N\)</span>, <span class="math inline">\(\tilde n\)</span> is the harmonic mean of the population sample sizes, i.e., <span class="math inline">\(\tilde n = \frac{1}{\frac{1}{N} \sum_{k=1}^{N} \frac{1}{n_k}}\)</span>, <span class="math inline">\(X_{kii}\)</span> is the frequency of genotype <span class="math inline">\(A_{i}A_{i}\)</span> in population <span class="math inline">\(k\)</span>, <span class="math inline">\(x_{ki}\)</span> is the frequency of allele <span class="math inline">\(A_{i}\)</span> in population <span class="math inline">\(k\)</span>, and <span class="math inline">\(n_k\)</span> is the sample size from population <span class="math inline">\(k\)</span>. Recall that <span class="math display">\[\begin{aligned}
F_{is} &amp;=&amp; 1 - {H_{i} \over H_{s}} \\
F_{st} &amp;=&amp; 1 - {H_{s} \over H_{t}} \\
F_{it} &amp;=&amp; 1 - {H_{i} \over H_{t}} \quad .\end{aligned}\]</span></p>
<h2 class="unnumbered" id="weir-and-cockerhams-theta">Weir and Cockerham’s <span class="math inline">\(\theta\)</span></h2>
<p>Weir and Cockerham <span class="citation" data-cites="WeirCockerham84"></span> describe the fundamental ideas behind this approach. Weir and Hill <span class="citation" data-cites="Weir-Hill-2002"></span> bring things up to date. Holsinger and Weir <span class="citation" data-cites="Holsinger-Weir-2009"></span> provide a less technical overview.<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a> Most, if not all, packages available now that estimate <span class="math inline">\(F_{ST}\)</span> provide estimates of <span class="math inline">\(\theta\)</span>. The most important difference between <span class="math inline">\(\theta\)</span> and <span class="math inline">\(G_{st}\)</span> and the reason why <span class="math inline">\(G_{st}\)</span> has fallen into disuse is that <span class="math inline">\(G_{st}\)</span> ignores an important source of sampling error that <span class="math inline">\(\theta\)</span> incorporates.</p>
<p>In many applications, especially in evolutionary biology, the subpopulations included in our sample are not an exhasutive sample of all populations. Moreover, even if we have sampled from every population there is now, we may not have sampled from every population there ever was. And even if we’ve sampled from every population there ever was, we know that there are random elements in any evolutionary process. Thus, if we could run the clock back and start it over again, the genetic composition of the populations we have might be rather different from that of the populations we sampled. In other words, our populations are, in many cases, best regarded as a random sample from a much larger set of populations that could have been sampled.</p>
<h3 class="unnumbered" id="even-more-gory-details">Even more gory details<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a></h3>
<p>Let <span class="math inline">\(x_{mn,i}\)</span> be an indicator variable such that <span class="math inline">\(x_{mn,i} = 1\)</span> if allele <span class="math inline">\(m\)</span> from individual <span class="math inline">\(n\)</span> is of type <span class="math inline">\(i\)</span> and is 0 otherwise. Clearly, the sample frequency <span class="math inline">\(\hat p_i =
\frac{1}{2N}\sum_{m=1}^2\sum_{n=1}^Nx_{mn,i}\)</span>, and <span class="math inline">\(E(\hat p_i) =
p_i\)</span>, <span class="math inline">\(i=1\dots A\)</span>. Assuming that alleles are sampled independently from the population <span class="math display">\[\begin{aligned}
E(x^2_{mn,i}) &amp;=&amp; p_i \\
E(x_{mn,i}x_{mn&#39;,i}) = E(x_{mn,i}x_{m&#39;n&#39;,i}) &amp;=&amp; p_i^2 + \sigma_{x_{mn,i}x_{m&#39;n&#39;,i}} \\
&amp;=&amp; p_i^2 + p_i(1-p_i)\theta\end{aligned}\]</span> where <span class="math inline">\(\sigma_{x_{mn,i}x_{m&#39;n&#39;,i}}\)</span> is the intraclass covariance for the indicator variables and <span class="math display">\[\theta = \frac{\sigma^2_{p_i}}{p_i(1-p_i)} \label{eq:theta-def}\]</span> is the scaled among population variance in allele frequency in the populations from which this population was sampled. Using (<a href="#eq:theta-def" data-reference-type="ref" data-reference="eq:theta-def">[eq:theta-def]</a>) we find after some algebra <span class="math display">\[\sigma^2_{\hat p_i} = p_i(1-p_i)\theta +
\frac{p_i(1-p_i)(1-\theta)}{2N} \quad .\]</span> The hat on <span class="math inline">\(\sigma^2_{\hat p_i}\)</span> indicates the <span><em>sample</em></span> variance of allele frequencies among popluations. A natural estimate for <span class="math inline">\(\theta\)</span> emerges using the method of moments when an analysis of variance is applied to indicator variables derived from samples representing more than one population.</p>
<h2 class="unnumbered" id="applying-g_st-and-theta">Applying <span class="math inline">\(G_{st}\)</span> and <span class="math inline">\(\theta\)</span></h2>
<p>If we return to the data that motivated this discussion, the results in Table <a href="#table:fst-comparison" data-reference-type="ref" data-reference="table:fst-comparison">2</a> show what we get from analyses of the <span class="math inline">\(GOT-1\)</span> data from <span><em>Isotoma petraea</em></span> (Table <a href="#table:isotoma" data-reference-type="ref" data-reference="table:isotoma">1</a>).</p>
<div id="table:fst-comparison">
<table>
<caption>Comparison of Wright’s <span class="math inline">\(F\)</span>-statistics when ignoring sampling effects with Nei’s <span class="math inline">\(G_{ST}\)</span> and Weir and Cockerham’s <span class="math inline">\(\theta\)</span>.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;"><span class="math inline">\(F_{is}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(F_{st}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(F_{it}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Direct</td>
<td style="text-align: center;">0.1372</td>
<td style="text-align: center;">0.2143</td>
<td style="text-align: center;">0.3221</td>
</tr>
<tr class="even">
<td style="text-align: center;">Nei</td>
<td style="text-align: center;">0.3092</td>
<td style="text-align: center;">0.2395</td>
<td style="text-align: center;">0.4746</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Weir &amp; Cockerham</td>
<td style="text-align: center;">0.5398</td>
<td style="text-align: center;">0.0387</td>
<td style="text-align: center;">0.5577</td>
</tr>
</tbody>
</table>
</div>
<p>But first a note on how you’ll see statistics like this reported in the literature. It can get a little confusing, because of the different symbols that are used. Sometimes you’ll see <span class="math inline">\(F_{is}\)</span>, <span class="math inline">\(F_{st}\)</span>, and <span class="math inline">\(F_{it}\)</span>. Sometimes you’ll see <span class="math inline">\(f\)</span>, <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(F\)</span>. And it will seem as if they’re referring to similar things. That’s because they are. They’re really just different symbols for the same thing (see Table <a href="#table:fst-theta" data-reference-type="ref" data-reference="table:fst-theta">3</a>).</p>
<div id="table:fst-theta">
<table>
<caption>Equivalent notations often encountered in descriptions of population genetic structure.</caption>
<tbody>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">Wright</td>
<td style="text-align: center;">Weir &amp; Cockerham</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(F_{it}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(F\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(F_{is}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(f\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(F_{st}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\theta\)</span></td>
</tr>
</tbody>
</table>
</div>
<p>Strictly speaking the symbols in Table <a href="#table:fst-theta" data-reference-type="ref" data-reference="table:fst-theta">3</a> are the <span><em>parameters</em></span>, i.e., values in the population that we try to estimate. We should put hats over any values estimated from data to indicate that they are estimates of the parameters, not the parameters themselves. But we’re usually a bit sloppy, and everyone knows that we’re presenting estimates, so we usually leave off the hats.</p>
<h1 class="unnumbered" id="an-example-from-wright">An example from Wright</h1>
<p>Hierarchical analysis of variation in the frequency of the Standard chromosome arrangement of <span><em>Drosophila pseudoobscura</em></span> in the western United States (data from <span class="citation" data-cites="Dobzhansky-Epling-1944"></span>, analysis from <span class="citation" data-cites="Wright-1978"></span>). Wright uses his rather peculiar method of accounting for sampling error. I haven’t gone back to the original data and used a more modern method of analysis.<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a></p>
<p>66 populations (demes) studied. Demes are grouped into eight regions. The regions are grouped into four primary subdivisions.</p>
<h2 class="unnumbered" id="results">Results</h2>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes within individuals relative to regions (<span class="math inline">\(F_{IR}\)</span>):</td>
<td style="text-align: center;">0.0444</td>
</tr>
<tr class="even">
<td style="text-align: left;">Correlation of gametes within regions relative to subdivisions (<span class="math inline">\(F_{RS}\)</span>):</td>
<td style="text-align: center;">0.0373</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Correlation of gametes within subdivisions relative to total (<span class="math inline">\(F_{ST}\)</span>):</td>
<td style="text-align: center;">0.1478</td>
</tr>
<tr class="even">
<td style="text-align: left;">Correlation of gametes in sample (<span class="math inline">\(F_{IT}\)</span>):</td>
<td style="text-align: center;">0.2160</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[1 - F_{IT} = (1 - F_{IR})(1 - F_{RS})(1 - F_{ST})\]</span></p>
<h2 class="unnumbered" id="interpretation">Interpretation</h2>
<p>There is relatively little inbreeding within regions (<span class="math inline">\(F_{IR}\)</span> = 0.04) and relatively little genetic differentiation among regions within subdivisions (<span class="math inline">\(F_{RS} = 0.04\)</span>). There is, however, substantial genetic differentiation among the subdivisions (<span class="math inline">\(F_{ST} = 0.15\)</span>).</p>
<p>Thus, an explanation for the chromosomal diversity that predicted great local differentiation and little or no differentiation at a large scale would be inconsistent with these observations.</p>
<h1 class="unnumbered" id="creative-commons-license">Creative Commons License</h1>
<p>These notes are licensed under the Creative Commons Attribution License. To view a copy of this license, visit https://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305, USA.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Those of you who’ve been in EEB for a while will know that these are probably different species, but humor me, and forget that you know that.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>If we ignore sampling error.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>For the time being, I’m going to assume that we know the allele frequencies without error, i.e., that we didn’t have to estimate them from data. We’ll deal with real life, i.e., how we can detect the Wahlund effect when we have to <span><em>estimate</em></span> allele freqeuncies from data, a little later.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>We’d get the same result by relaxing this assumption, but the algebra gets messier, so why bother?<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>For example, if we combine samples from different years or across age classes of long-lived organisms, we may see a deficienty of heterozygotes in the sample purely as a result of allele frequency differences across years. Remember that I told you one of the assumptions underlying derivation of the Hardy-Weinberg principle is that generations are non-overlapping? This is why.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>If you’re curious about this, feel free to ask, but I’ll have to dig out my copy of Li <span class="citation" data-cites="Li-1976"></span> to answer. I don’t carry those details around in my head.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>And this is what we predicted when we started.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>The reason for the subscript will become apparent later. It’s also <span><em>very</em></span> important to notice that I’m defining <span class="math inline">\(F_{ST}\)</span> here in terms of the population parameters <span class="math inline">\(p\)</span> and <span class="math inline">\(\mbox{Var}(p)\)</span>. Again, we’ll return to the problem of how to <span> <em>estimate</em></span> <span class="math inline">\(F_{ST}\)</span> from data a little later.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>To be precise, it is a form of positive assortative mating in which the choice of mates is based on geographical proximity.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>I say “one way”, because there are several other ways to talk about <span class="math inline">\(F_{st}\)</span>, too. But we won’t talk about them until later.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>At least it’s easy once you’ve been shown how.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>Please remember that we’re assuming we know those frequencies exactly. In real applications, of course, we’ll <span> <em>estimate</em></span> those frequencies from data, so we’ll have to account for sampling error when we actually try to estimate these things. If you’re getting the impression that I think the distinction between allele frequencies as <span><em>parameters</em></span>, i.e., the real allele frequency in the population , and allele frequencies as <span> <em>estimates</em></span>, i.e., the sample frequencies from which we hope to estimate the paramters, is really important, you’re getting the right impression.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Are you beginning to see how peculiar I am? Do you know anyone else who gets a kick out of playing around with formulas and equations.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>It takes a fair amount of algebra to show that this definition of <span class="math inline">\(F_{st}\)</span> is equivalent to the one I showed you before, so you’ll just have to take my word for it.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>Probably because he published in English and Mal<span>é</span>cot published in French.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>The Hardy-Weinberg proportions should probably be referred to as the Hardy-Weinberg-Castle proportions too, since Castle pointed out the same principle. For some reason, though, his demonstration didn’t have the impact that Hardy’s and Weinberg’s did. So we generally talk about the Hardy-Weinberg principle.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>And as we’ll soon see, I’m not too crazy about one of these three. To my mind, there are really only two approaches that anyone should consider, and those two approaches are really just variants of the same basic idea.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>This is, as you have probably already guessed, my personal favorite. We’ll talk about it next time.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>See <span class="citation" data-cites="Weir-1996"></span> for details.<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p><span class="math inline">\(\mbox{P}(k|p,N) = {N \choose k}p^k(1-p)^{N-k}\)</span>. The algebra in getting from the first line to the second is a little complicated, but feel free to ask me about it if you’re intersted.<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>Notice that I’m using a hat here to refer to a statistical estimate. Remember when I told you I’d be using hats for a couple of different purposes? Well, this is the second one.<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22" role="doc-endnote"><p>If you’re wondering how I got from the second equation for <span class="math inline">\(\hat H\)</span> to the last one, ask me about it or read the gory details section that follows. TAMO is short for “Then a miracle occurs.” You’ll see that acronym repeatedly this semester.<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23" role="doc-endnote"><p>Skip this part unless you are <span><em>really, really</em></span> interested in how I got from the second equation to the third equation in the last paragraph. This is more likely to confuse you than help unless you know that the variance of a binomial sample is <span class="math inline">\(np(1-p)\)</span> and that <span class="math inline">\(E(k^2) = \hbox{Var}(p) +
p^2\)</span>.<a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24" role="doc-endnote"><p>There’s actually a third source of error that we’ll get to in a moment. The populations we’re sampling from are the product of an evolutionary process, and since the populations aren’t of infinite size, drift has played a role in determining allele frequencies in them. As a result, if we were to go back in time and re-run the evolutionary process, we’d end up with a different set of real allele frequency differences. We’ll talk about this more in just a moment when we get to Weir and Cockerham’s statistics.<a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25" role="doc-endnote"><p><span><code>Popgene</code></span> estimates <span class="math inline">\(G_{st}\)</span>, but I don’t think it’s been updated since 2000. <span><code>FSTAT</code></span> also estimates gene diversities, but the most recent version is from 2002.<a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26" role="doc-endnote"><p>There’s a reason for this that we’ll get to in a moment. It’s alluded to in the last footnote.<a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27" role="doc-endnote"><p>It is also one big reason why most people use Weir and Cockerham’s <span class="math inline">\(\theta\)</span>. There’s readily available software that calculates it for you.<a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28" role="doc-endnote"><p>We also talk a bit more about how <span class="math inline">\(F\)</span>-statistics can be used. If you just can’t get enough of this, I suggest you take a look at Verity and Nichols <span class="citation" data-cites="Verity-Nichols-2014"></span>. They provide a really solid analysis of <span class="math inline">\(F_{ST}\)</span>, <span class="math inline">\(G_{ST}\)</span>, and some related statistics.<a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29" role="doc-endnote"><p>This is even worse than the last time. I include it for completeness only. I really don’t expect anyone (unless they happen to be a statistician) to be able to understand these details. I wouldn’t recommend spending time trying to understand this unless you really, really want to understand the mathematical underpinnings of Weir and Cockerham’s statistics. I’ve explained the fundamental principles in the text. This is just a lot of algebra, which admittedly entertains some of us who have a perverse fascination with these things.<a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30" role="doc-endnote"><p>Sounds like it might be a good project, doesn’t it? We’ll see.<a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
