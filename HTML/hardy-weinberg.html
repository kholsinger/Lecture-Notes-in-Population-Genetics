<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>The Hardy-Weinberg Principle and estimating allele frequencies</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="pandoc.css" />
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">The Hardy-Weinberg Principle and estimating allele frequencies</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-genetic-composition-of-populations">The genetic composition of populations</a></li>
<li><a href="#derivation-of-the-hardy-weinberg-principle">Derivation of the Hardy-Weinberg principle</a></li>
<li><a href="#the-hardy-weinberg-principle">The Hardy-Weinberg principle</a></li>
<li><a href="#estimating-allele-frequencies">Estimating allele frequencies</a>
<ul>
<li><a href="#what-is-a-maximum-likelihood-estimate">What is a maximum-likelihood estimate?</a></li>
</ul></li>
<li><a href="#an-introduction-to-bayesian-inference">An introduction to Bayesian inference</a>
<ul>
<li><a href="#estimating-allele-frequencies-with-two-alleles">Estimating allele frequencies with two alleles</a></li>
</ul></li>
<li><a href="#returning-to-the-abo-example">Returning to the ABO example</a></li>
<li><a href="#creative-commons-license">Creative Commons License</a></li>
</ul>
</nav>
<h1 class="unnumbered" id="introduction">Introduction</h1>
<p>To keep things relatively simple, we’ll spend much of our time in the first part of this course talking about variation at a single genetic locus, even though alleles at many different loci are involved in expression of most morphological or physiological traits. Towards the end of the course, we’ll study the genetics of continuous (quantitative) variation, but until then you can asssume that I’m talking about variation at a single locus unless I specifically say otherwise.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<h1 class="unnumbered" id="the-genetic-composition-of-populations">The genetic composition of populations</h1>
<p>When I talk about the genetic composition of a population, I’m referring to three aspects of genetic variation within that population:<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<ol>
<li><p>The number of alleles at a locus.</p></li>
<li><p>The frequency of alleles at the locus.</p></li>
<li><p>The frequency of genotypes at the locus.</p></li>
</ol>
<p>It may not be immediately obvious why we need both (2) and (3) to describe the genetic composition of a population, so let me illustrate with two hypothetical populations:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Population 1</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">50</td>
</tr>
<tr class="even">
<td style="text-align: left;">Population 2</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">25</td>
</tr>
</tbody>
</table>
<p>It’s easy to see that the frequency of <span class="math inline">\(A_1\)</span> is 0.5 in both populations,<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> but the genotype frequencies are very different. In point of fact, we don’t need both genotype and allele frequencies. We could get away with only genotype frequencies, since we can always calculate allele frequencies from genotype frequencies. But there are fewer allele frequencies than genotype frequenciesonly one allele frequency when there are two alleles at a locus. So working with allele frequencies is more convenient when we can get away with it. The challenge is that we can’t get genotype frequencies from allele frequencies unless <span class="math inline">\(\dots\)</span></p>
<h1 class="unnumbered" id="derivation-of-the-hardy-weinberg-principle">Derivation of the Hardy-Weinberg principle</h1>
<p>We saw last time using the data from <span><em>Zoarces viviparus</em></span> that we can describe empirically and algebraically how genotype frequencies in one generation are related to genotype frequencies in the next. Let’s explore that a bit further. To do so we’re going to use a technique that is broadly useful in population genetics,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> i.e., we’re going to construct a mating table. A mating table consists of three components:</p>
<ol>
<li><p>A list of all possible genotype pairings.</p></li>
<li><p>The frequency with which each genotype pairing occurs.</p></li>
<li><p>The genotypes produced by each pairing.</p></li>
</ol>
<table>
<tbody>
<tr class="odd">
<td style="text-align: right;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: right;">Female <span class="math inline">\(\times\)</span> Male</td>
<td style="text-align: center;">Frequency</td>
<td style="text-align: center;"><span class="math inline">\(A_1A_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(A_1A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(A_2A_2\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(A_1A_1 \times A_1A_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{11}^2\)</span></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{11}x_{12}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{11}x_{22}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: right;"><span class="math inline">\(A_1A_2 \times A_1A_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{12}x_{11}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{12}^2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{4}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{4}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{12}x_{22}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(A_2A_2 \times A_1A_1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{22}x_{11}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: right;"><span class="math inline">\(A_1A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{22}x_{12}\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\frac{1}{2}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: right;"><span class="math inline">\(A_2A_2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(x_{22}^2\)</span></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>Notice that I’ve distinguished matings by both maternal and paternal genotype. While it’s not necessary for this example, we will see examples later in the course where it’s important to distinguish a mating in which the female is <span class="math inline">\(A_1A_1\)</span> and the male is <span class="math inline">\(A_1A_2\)</span> from ones in which the female is <span class="math inline">\(A_1A_2\)</span> and the male is <span class="math inline">\(A_1A_1\)</span>. You are also likely to be surprised to learn that just in writing this table we’ve already made three assumptions about the transmission of genetic variation from one generation to the next:</p>
<dl>
<dt>Assumption #1</dt>
<dd><p>Genotype frequencies are the same in males and females, e.g., <span class="math inline">\(x_{11}\)</span> is the frequency of the <span class="math inline">\(A_1A_1\)</span> genotype in both males and females.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
</dd>
<dt>Assumption #2</dt>
<dd><p>Genotypes mate at random <span><em>with respect to their genotype at this particular locus</em></span>.</p>
</dd>
<dt>Assumption #3</dt>
<dd><p>Meiosis is fair. More specifically, we assume that there is no segregation distortion; no gamete competition; no differences in the developmental ability of eggs, or the fertilization ability of sperm.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> It may come as a surprise to you, but there are alleles at some loci in some organisms that subvert the Mendelian rules, e.g., the <span class="math inline">\(t\)</span> allele in house mice, segregation distorter in <span><em>Drosophila melanogaster</em></span>, and spore killer in <span><em>Neurospora crassa</em></span>.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
</dd>
</dl>
<p>Now that we have this table we can use it to calculate the frequency of each genotype in newly formed zygotes in the population,<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> provided that we’re willing to make three additional assumptions:</p>
<dl>
<dt>Assumption #4</dt>
<dd><p>There is no input of new genetic material, i.e., gametes are produced without mutation, and all offspring are produced from the union of gametes within this population, i.e., no migration from outside the population.</p>
</dd>
<dt>Assumption #5</dt>
<dd><p>The population is of infinite size so that the actual frequency of matings is equal to their expected frequency and the actual frequency of offspring from each mating is equal to the Mendelian expectations.</p>
</dd>
<dt>Assumption #6</dt>
<dd><p>All matings produce the same number of offspring, on average.</p>
</dd>
</dl>
<p>Taking these three assumptions together allows us to conclude that the frequency of a particular genotype in the pool of newly formed zygotes is <span class="math display">\[\sum(\hbox{frequency of mating})(\hbox{frequency of genotype produce
  from mating}) \quad .\]</span> So</p>
<p><span class="math display">\[\begin{aligned}
\hbox{freq.}(A_1A_1\hbox{ in zygotes}) &amp;=&amp;
   x_{11}^2 + \frac{1}{2}x_{11}x_{12} + \frac{1}{2}x_{12}x_{11}
   + \frac{1}{4}x_{12}^2 \\
&amp;=&amp; x_{11}^2 + x_{11}x_{12} + \frac{1}{4}x_{12}^2 \\
&amp;=&amp; (x_{11} + x_{12}/2)^2 \\
&amp;=&amp; p^2 \\
\hbox{freq.}(A_1A_2\hbox{ in zygotes}) &amp;=&amp; 2pq \\
\hbox{freq.}(A_2A_2\hbox{ in zygotes}) &amp;=&amp; q^2 \\\end{aligned}\]</span> Those frequencies probably look pretty familiar to you. They are, of course, the familiar Hardy-Weinberg proportions. But we’re not done yet. In order to say that these proportions will also be the genotype proportions of adults in the progeny generation, we have to make two more assumptions:</p>
<dl>
<dt>Assumption #7</dt>
<dd><p>Generations do not overlap.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
</dd>
<dt>Assumption #8</dt>
<dd><p>There are no differences among genotypes in the probability of survival.</p>
</dd>
</dl>
<h1 class="unnumbered" id="the-hardy-weinberg-principle">The Hardy-Weinberg principle</h1>
<p>After a single generation in which <span><em>all</em></span> eight of the above assumptions are satisfied</p>
<p><span class="math display">\[\begin{aligned}
\hbox{freq.}(A_1A_1\hbox{ in adults}) &amp;=&amp; p^2 \label{eq:hw-p2} \\
\hbox{freq.}(A_1A_2\hbox{ in adults}) &amp;=&amp; 2pq \label{eq:hw-2pq} \\
\hbox{freq.}(A_2A_2\hbox{ in adults}) &amp;=&amp; q^2 \label{eq:hw-q2}\end{aligned}\]</span></p>
<p>It’s vital to understand the logic here.</p>
<ol>
<li><p>If Assumptions #1–#8 are true, then equations <a href="#eq:hw-p2" data-reference-type="ref" data-reference="eq:hw-p2">[eq:hw-p2]</a>–<a href="#eq:hw-q2" data-reference-type="ref" data-reference="eq:hw-q2">[eq:hw-q2]</a> <span><strong>must</strong></span> be true.</p></li>
<li><p>If genotypes are <span><em>not</em></span> in Hardy-Weinberg proportions, one or more of Assumptions #1–#8 <span><strong>must</strong></span> be false.</p></li>
<li><p>If genotypes are in Hardy-Weinberg proportions, one or more of Assumptions #1–#8 may still be violated.</p></li>
<li><p>Assumptions #1–#8 are <span><em>sufficient</em></span> for Hardy-Weinberg to hold, but they are not <span><em>necessary</em></span> for Hardy-Weinberg to hold.</p></li>
</ol>
<p>Point (2) is why the Hardy-Weinberg principle is so important. There isn’t a population of any organism anywhere in the world that satisfies all 8 assumptions, even for a single generation.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> But <span><em>all</em></span> possible evolutionary processes within populations cause a violation of at least one of these assumptions. Departures from Hardy-Weinberg are one way in which we can detect those processes and estimate their magnitude.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
<h1 class="unnumbered" id="estimating-allele-frequencies">Estimating allele frequencies</h1>
<p>Before we can determine whether genotypes in a population are in Hardy-Weinberg proportions, we need to be able to estimate the frequency of both genotypes and alleles. This is easy when you can identify all of the alleles within genotypes, but suppose that we’re trying to estimate allele frequencies in the ABO blood group system in humans. Then we have a situation that looks like this:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Phenotype</th>
<th style="text-align: right;">A</th>
<th style="text-align: right;">AB</th>
<th style="text-align: right;">B</th>
<th style="text-align: right;">O</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Genotype(s)</td>
<td style="text-align: right;">aa ao</td>
<td style="text-align: right;">ab</td>
<td style="text-align: right;">bb bo</td>
<td style="text-align: right;">oo</td>
</tr>
<tr class="even">
<td style="text-align: left;">No. in sample</td>
<td style="text-align: right;"><span class="math inline">\(N_A\)</span></td>
<td style="text-align: right;"><span class="math inline">\(N_{AB}\)</span></td>
<td style="text-align: right;"><span class="math inline">\(N_{B}\)</span></td>
<td style="text-align: right;"><span class="math inline">\(N_O\)</span></td>
</tr>
</tbody>
</table>
<p>Now we can’t directly count the number of <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(o\)</span> alleles. What do we do? Well, more than 50 years ago, some geneticists figured out how with a method they called “gene counting” <span class="citation" data-cites="Ceppellini-etal-1955"></span> and that statisticians later generalized for a wide variety of purposes and called the EM algorithm <span class="citation" data-cites="Dempster-etal-1977"></span>. It uses a trick you’ll see repeatedly through this course. When we don’t know something we want to know, we pretend that we know it and do some calculations with what we just pretended to know. If we’re lucky, we can fiddle with our calculations a bit to relate the thing that we pretended to know to something we actually do know so we can figure out what we wanted to know. Make sense? Probably not. Let’s try an example and see if that helps.</p>
<p>If we knew <span class="math inline">\(p_a\)</span>, <span class="math inline">\(p_b\)</span>, and <span class="math inline">\(p_o\)</span>, we could figure out how many individuals with the <span class="math inline">\(A\)</span> phenotype have the <span class="math inline">\(aa\)</span> genotype and how many have the <span class="math inline">\(ao\)</span> genotype, namely <span class="math display">\[\begin{aligned}
N_{aa} &amp;=&amp; n_A \left({p_a^2 \over p_a^2 + 2p_ap_o}\right) \\
N_{ao} &amp;=&amp; n_A \left({2p_ap_o \over p_a^2 + 2p_ap_o}\right) \quad .\end{aligned}\]</span> Obviously we could do the same thing for the <span class="math inline">\(B\)</span> phenotype: <span class="math display">\[\begin{aligned}
N_{bb} &amp;=&amp; n_B \left({p_b^2 \over p_b^2 + 2p_bp_o}\right) \\
N_{bo} &amp;=&amp; n_B \left({2p_bp_o \over p_b^2 + 2p_bp_o}\right) \quad .\end{aligned}\]</span> Notice that <span class="math inline">\(N_{ab} = N_{AB}\)</span> and <span class="math inline">\(N_{oo} = N_O\)</span> (lowercase subscripts refer to genotypes, uppercase to phenotypes). If we knew all this, then we could calculate <span class="math inline">\(p_a\)</span>, <span class="math inline">\(p_b\)</span>, and <span class="math inline">\(p_o\)</span> from <span class="math display">\[\begin{aligned}
p_a &amp;=&amp; {2N_{aa} + N_{ao} + N_{ab} \over 2N} \\
p_b &amp;=&amp; {2N_{bb} + N_{bo} + N_{ab} \over 2N} \\
p_o &amp;=&amp; {2N_{oo} + N_{ao} + N_{bo} \over 2N} \quad ,\end{aligned}\]</span> where <span class="math inline">\(N\)</span> is the total sample size.</p>
<p>Surprisingly enough we can actually estimate the allele frequencies by using this trick. Just take a guess at the allele frequencies. Any guess will do. Then calculate <span class="math inline">\(N_{aa}\)</span>, <span class="math inline">\(N_{ao}\)</span>, <span class="math inline">\(N_{bb}\)</span>, <span class="math inline">\(N_{bo}\)</span>, <span class="math inline">\(N_{ab}\)</span>, and <span class="math inline">\(N_{oo}\)</span> as described in the preceding paragraph.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> That’s the <span><strong>E</strong></span>xpectation part the EM algorithm. Now take the values for <span class="math inline">\(N_{aa}\)</span>, <span class="math inline">\(N_{ao}\)</span>, <span class="math inline">\(N_{bb}\)</span>, <span class="math inline">\(N_{bo}\)</span>, <span class="math inline">\(N_{ab}\)</span>, and <span class="math inline">\(N_{oo}\)</span> that you’ve calculated and use them to calculate new values for the allele frequencies. That’s the <span><strong>M</strong></span>aximization part of the EM algorithm. It’s called “maximization” because what you’re doing is calculating maximum-likelihood estimates of the allele frequencies, given the observed (and made up) genotype counts.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> Chances are your new values for <span class="math inline">\(p_a\)</span>, <span class="math inline">\(p_b\)</span>, and <span class="math inline">\(p_o\)</span> won’t match your initial guesses, but<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> if you take these new values and start the process over and repeat the whole sequence several times, eventually the allele frequencies you get out at the end match those you started with. These are maximum-likelihood estimates of the allele frequencies.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>Consider the following example:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Phenotype</td>
<td style="text-align: right;">A</td>
<td style="text-align: right;">AB</td>
<td style="text-align: right;">AB</td>
<td style="text-align: right;">O</td>
</tr>
<tr class="even">
<td style="text-align: left;">No. in sample</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">15</td>
</tr>
</tbody>
</table>
<p>We’ll start with the guess that <span class="math inline">\(p_a = 0.33\)</span>, <span class="math inline">\(p_b = 0.33\)</span>, and <span class="math inline">\(p_o = 0.34\)</span>. With that assumption we would calculate that <span class="math inline">\(25(0.33^2/(0.33^2 + 2(0.33)(0.34))) = 8.168\)</span> of the A phenotypes in the sample have genotype <span class="math inline">\(aa\)</span>, and the remaining 16.832 have genotype <span class="math inline">\(ao\)</span>. Similarly, we can calculate that 8.168 of the B phenotypes in the population sample have genotype <span class="math inline">\(bb\)</span>, and the remaining 16.832 have genotype <span class="math inline">\(bo\)</span>. Now that we have a guess about how many individuals of each genotype we have,<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> we can calculate a new guess for the allele frequencies, namely <span class="math inline">\(p_a = 0.362\)</span>, <span class="math inline">\(p_b = 0.362\)</span>, and <span class="math inline">\(p_o = 0.277\)</span>. By the time we’ve repeated this process four more times, the allele frequencies aren’t changing anymore, and the maximum likelihood estimate of the allele frequencies is <span class="math inline">\(p_a = 0.372\)</span>, <span class="math inline">\(p_b = 0.372\)</span>, and <span class="math inline">\(p_o = 0.256\)</span>.</p>
<h2 class="unnumbered" id="what-is-a-maximum-likelihood-estimate">What is a maximum-likelihood estimate?</h2>
<p>I just told you that the method I described produces “maximum-likelihood estimates” for the allele frequencies, but I haven’t told you what a maximum-likelihood estimate <span><em>is</em></span>. The good news is that you’ve been using maximum-likelihood estimates for as long as you’ve been estimating anything, without even knowing it. Although it will take me a while to explain it, the idea is actually pretty simple.</p>
<p>Suppose we had a sock drawer with two colors of socks, red and green. And suppose we were interested in estimating the proportion of red socks in the drawer. One way of approaching the problem would be to mix the socks well, close our eyes, take one sock from the drawer, record its color and replace it. Suppose we do this <span class="math inline">\(N\)</span> times. We know that the number of red socks we’ll get might be different the next time, so the number of red socks we actually get is a random variable. Let’s call that random variable <span class="math inline">\(K\)</span>. Now suppose in our actual experiment we find <span class="math inline">\(k\)</span> red socks, i.e., the value our random variable takes on is <span class="math inline">\(k\)</span> or putting it in an equation: <span class="math inline">\(K=k\)</span>. If we knew <span class="math inline">\(p\)</span>, the proportion of red socks in the drawer, we could calculate the probability of getting the data we observed, namely <span class="math display">\[\mbox{P}(K=k|p) = {N \choose k} p^k (1-p)^{(N-k)} \quad . \label{eq:binomial}\]</span> This is the <span><em>binomial probability distribution</em></span>. The part on the left side of the equation is read as “The probability that we get <span class="math inline">\(k\)</span> red socks in our sample <span><em>given</em></span> the value of <span class="math inline">\(p\)</span>.” The word “given” means that we’re calculating the probability of our data conditional on the (unknown) value <span class="math inline">\(p\)</span>.</p>
<p>Of course we don’t know <span class="math inline">\(p\)</span>, so what good does writing (<a href="#eq:binomial" data-reference-type="ref" data-reference="eq:binomial">[eq:binomial]</a>) do? Well, suppose we reverse the question to which equation (<a href="#eq:binomial" data-reference-type="ref" data-reference="eq:binomial">[eq:binomial]</a>) is an answer and call the expression in (<a href="#eq:binomial" data-reference-type="ref" data-reference="eq:binomial">[eq:binomial]</a>) the “likelihood of the data.” Suppose further that we find the value of <span class="math inline">\(p\)</span> that makes the likelihood bigger than any other value we could pick.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> Then <span class="math inline">\(\hat p\)</span> is the maximum-likelihood estimate of <span class="math inline">\(p\)</span>.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<p>In the case of the ABO blood group that we just talked about, the likelihood is a bit more complicated <span class="math display">\[{N \choose N_A N_{AB} N_B N_O}
\left(p_a^2 + 2p_ap_o\right)^{N_A}
2p_ap_b^{N_{AB}}
\left(p_b^2 + 2p_bp_o\right)^{N_B}
\left(p_o^2\right)^{N_O}\]</span> This is a <span><em>multinomial probability distribution</em></span>. It turns out that one way to find the values of <span class="math inline">\(p_a\)</span>, <span class="math inline">\(p_b\)</span>, and <span class="math inline">\(p_o\)</span> is to use the EM algorithm I just described.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> There isn’t a simple formula that allows us to write down an expression for the maximum-likelihood estimate of the allele frequencies in terms of the phenotype frequencies. We have to use an algorithm to find them, and the EM algorithm happens to be a particularly convenient algorithm to use.</p>
<h1 class="unnumbered" id="an-introduction-to-bayesian-inference">An introduction to Bayesian inference</h1>
<p>Maximum-likelihood estimates have a lot of nice features, but they are also a slightly backwards way of looking at the world. The likelihood of the data is the probability of the data, <span class="math inline">\(x\)</span>, given parameters that we don’t know, <span class="math inline">\(\phi\)</span>, i.e, <span class="math inline">\(\mbox{P}(x|\phi)\)</span>. It seems a lot more natural to think about the probability that the unknown parameter takes on some value, given the data, i.e., <span class="math inline">\(\mbox{P}(\phi|x)\)</span>. Surprisingly, these two quantities are closely related. Bayes’ Theorem tells us that <span class="math display">\[\mbox{P}(\phi|x) = \frac{\mbox{P}(x|\phi)\mbox{P}(\phi)}{\mbox{P}(x)} \quad .
\label{eq:bayes}\]</span> We refer to <span class="math inline">\(\mbox{P}(\phi|x)\)</span> as the <span><em>posterior distribution</em></span> of <span class="math inline">\(\phi\)</span>, i.e., the probability that <span class="math inline">\(\phi\)</span> takes on a particular value given the data we’ve observed, and to <span class="math inline">\(\mbox{P}(\phi)\)</span> as the <span> <em>prior distribution</em></span> of <span class="math inline">\(\phi\)</span>, i.e., the probability that <span class="math inline">\(\phi\)</span> takes on a particular value <span><em>before</em></span> we’ve looked at any data. Notice how the relationship in (<a href="#eq:bayes" data-reference-type="ref" data-reference="eq:bayes">[eq:bayes]</a>) mimics the logic we use to learn about the world in everyday life. We start with some prior beliefs, <span class="math inline">\(\mbox{P}(\phi)\)</span>, and modify them on the basis of data or experience, <span class="math inline">\(\mbox{P}(x|\phi)\)</span>, to reach a conclusion, <span class="math inline">\(\mbox{P}(\phi|x)\)</span>. That’s the underlying logic of Bayesian inference.</p>
<h2 class="unnumbered" id="estimating-allele-frequencies-with-two-alleles">Estimating allele frequencies with two alleles</h2>
<p>Let’s suppose we’ve collected data from a population of <span><em>Protea repens</em></span><a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> and have found 7 alleles coding for the <span><em>fast</em></span> allele at a enzyme locus encoding glucose-phosphate isomerase in a sample of 20 alleles. We want to estimate the frequency of the <span><em>fast</em></span> allele. The maximum-likelihood estimate is <span class="math inline">\(7/20 = 0.35\)</span>, which we got by finding the value of <span class="math inline">\(p\)</span> that maximizes <span class="math display">\[\begin{aligned}
\mbox{P}(k|N,p) &amp;=&amp; {N \choose k} p^k (1-p)^{N-k} \quad ,\end{aligned}\]</span> where <span class="math inline">\(N=20\)</span> and <span class="math inline">\(k=7\)</span>. A Bayesian uses the same likelihood, but has to specify a prior distribution for <span class="math inline">\(p\)</span>. If we didn’t know anything about the allele frequency at this locus in <span><em>P. repens</em></span> before starting the study, it makes sense to express that ignorance by choosing <span class="math inline">\(\mbox{P}(p)\)</span> to be a uniform random variable on the interval <span class="math inline">\([0,1]\)</span>. That means we regarded all values of <span class="math inline">\(p\)</span> as equally likely prior to collecting the data.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></p>
<p>Until the early 1990s<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a> it was necessary to do a bunch of complicated calculus to combine the prior with the likelihood to get a posterior. Since the early 1990s statisticians have used a simulation approach, Monte Carlo Markov Chain sampling, to construct numerical samples from the posterior. For the problems encountered in this course, we’ll mostly be using the freely available software package <span><code>Stan</code></span> through its interface in <span><code>R</code></span>, <span><code>rstan</code></span>, to implement Bayesian analyses. For the problem we just encountered, here’s the code that’s needed to get our results:<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a></p>
<pre><code>data {
  int&lt;lower=0&gt; N;     // the sample size
  int&lt;lower=0&gt; k;     // the number of A_1 alleles observed
}

parameters {
  real&lt;lower=0, upper=1&gt; p;  // the allele frequency
}

model {
  // likelihood
  //
  k ~ binomial(N, p);

  // prior
  p ~ uniform(0.0, 1.0);
}</code></pre>
<p>We can run this is in <span><code>R</code></span> by <span><code>source()</code></span>’ing the following code. Remember that in our fictitious example, we found 7 fast alleles in a sample of 20, i.e., <span class="math inline">\(k=7\)</span> and <span class="math inline">\(N=20\)</span>.</p>
<pre><code>## Load the rstan library
##
library(rstan)

## set the number of chains to the number of cores in the computer
##
options(mc.cores = parallel::detectCores())

## set up the data
##   N: sample size
##   k: number of A1 alleles
stan_data &lt;- list(N = 20,
                  k = 7)

## Invoke stan
##
fit &lt;- stan(&quot;binomial-model.stan&quot;,
            data = stan_data,
            refresh = 0)

## print the results on the console with 3 digits after the decimal
##
print(fit, digits = 3)</code></pre>
<p>Here’s what you’ll see in the terminal.<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a></p>
<pre><code>&gt; source(&quot;binomial-model.R&quot;)
Loading required package: StanHeaders
Loading required package: ggplot2
rstan (Version 2.21.2, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)
Inference for Stan model: binomial-model.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

        mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff  Rhat
p      0.360   0.003 0.099   0.179   0.289   0.357   0.424   0.561  1475 1.001
lp__ -14.926   0.017 0.719 -16.901 -15.088 -14.646 -14.470 -14.421  1691 1.000

Samples were drawn using NUTS(diag_e) at Sat Jun  5 16:54:55 2021.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&gt;</code></pre>
<p>Most of the column headings should be fairly self-explanatory. <span><code> mean</code></span> is our best guess for the value for the frequency of the <span> <em>fast</em></span> allele, the posterior mean of <span class="math inline">\(p\)</span>. <span><code>sd</code></span> is the posterior standard deviation of <span class="math inline">\(p\)</span>. It’s our best guess of the uncertainty associated with our estimate of the frequency of the <span><em>fast</em></span> allele. The 2.5%, 50%, and 97.5% columns are the percentiles of the posterior distribution. The [2.5%, 97.5%] interval is the 95% credible interval, which is analogous to the 95% confidence interval in classical statistics, except that we can say that there’s a 95% chance that the frequency of the <span><em>fast</em></span> allele lies within this interval.<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a> Since the results are from a simulation, different runs will produce slightly different results. In this case, we have a posterior mean of about 0.36 (as opposed to the maximum-likelihood estimate of 0.35), and there is a 95% chance that <span class="math inline">\(p\)</span> lies in the interval [0.18, 0.56].</p>
<h1 class="unnumbered" id="returning-to-the-abo-example">Returning to the ABO example</h1>
<p>Here’s data from the ABO blood group:<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a></p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Phenotype</td>
<td style="text-align: center;">A</td>
<td style="text-align: center;">AB</td>
<td style="text-align: center;">B</td>
<td style="text-align: center;">O</td>
<td style="text-align: center;">Total</td>
</tr>
<tr class="even">
<td style="text-align: left;">Observed</td>
<td style="text-align: center;">862</td>
<td style="text-align: center;">131</td>
<td style="text-align: center;">365</td>
<td style="text-align: center;">702</td>
<td style="text-align: center;">2060</td>
</tr>
</tbody>
</table>
<p>To estimate the underlying allele frequencies, <span class="math inline">\(p_A\)</span>, <span class="math inline">\(p_B\)</span>, and <span class="math inline">\(p_O\)</span>, we have to remember how the allele frequencies map to phenotype frequencies:<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a> <span class="math display">\[\begin{aligned}
\hbox{Freq}(A) &amp;=&amp; p_A^2 + 2p_Ap_O \\
\hbox{Freq}(AB) &amp;=&amp; 2p_Ap_B \\
\hbox{Freq}(B) &amp;=&amp; p_B^2 + 2p_Bp_O \\
\hbox{Freq}(O) &amp;=&amp; p_O^2 \quad .\end{aligned}\]</span> Hers’s the <span><code>Stan</code></span> code we use to estimate the allele frequencies:</p>
<pre><code>data {
  int&lt;lower=0&gt; N_A;
  int&lt;lower=0&gt; N_AB;
  int&lt;lower=0&gt; N_B;
  int&lt;lower=0&gt; N_O;
}

transformed data {
  int&lt;lower=0&gt; N[4];

  N[1] = N_A;
  N[2] = N_AB;
  N[3] = N_B;
  N[4] = N_O;
}

parameters {
  // the three allele frequencies add to 1
  //
  simplex[3] p;
}

transformed parameters {
  real&lt;lower=0, upper=1&gt; p_a;
  real&lt;lower=0, upper=1&gt; p_b;
  real&lt;lower=0, upper=1&gt; p_o;
  // the four phenotype frequencies add to 1
  //
  simplex[4] x;

  // allele frequencies
  //
  p_a = p[1];
  p_b = p[2];
  p_o = p[3];
  // phenotype frequencies
  //
  // A
  x[1] = p_a^2 + 2*p_a*p_o;
  // AB
  x[2] = 2*p_a*p_b;
  // B
  x[3] = p_b^2 + 2*p_b*p_o;
  // O
  x[4] = p_o^2;
}

model {
  // likelihood
  //
  N ~ multinomial(x);

  // prior
  //
  p ~ dirichlet(rep_vector(1.0, 3));
}</code></pre>
<p>The <span><code>dirichlet()</code></span> prior produces a uniform distribution across all three allele frequencies while ensuring that they sum to 1. Here are the results of the analysis:</p>
<pre><code>&gt; source(&quot;abo-model.R&quot;)
Inference for Stan model: abo-model.
4 chains, each with iter=2000; warmup=1000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

          mean se_mean    sd      2.5%       25%       50%       75%     97.5% n_eff  Rhat
p[1]     0.281   0.000 0.008     0.266     0.276     0.281     0.287     0.297  3814 1.000
p[2]     0.129   0.000 0.005     0.119     0.126     0.129     0.133     0.140  3685 1.000
p[3]     0.589   0.000 0.008     0.573     0.584     0.589     0.595     0.605  3428 1.001
p_a      0.281   0.000 0.008     0.266     0.276     0.281     0.287     0.297  3814 1.000
p_b      0.129   0.000 0.005     0.119     0.126     0.129     0.133     0.140  3685 1.000
p_o      0.589   0.000 0.008     0.573     0.584     0.589     0.595     0.605  3428 1.001
x[1]     0.411   0.000 0.010     0.391     0.404     0.411     0.418     0.431  4033 1.000
x[2]     0.073   0.000 0.003     0.067     0.071     0.073     0.075     0.079  3417 1.001
x[3]     0.169   0.000 0.007     0.156     0.164     0.169     0.174     0.183  3764 1.000
x[4]     0.347   0.000 0.010     0.328     0.341     0.347     0.354     0.366  3430 1.001
lp__ -2506.009   0.022 0.963 -2508.531 -2506.366 -2505.715 -2505.316 -2505.068  1915 1.000

Samples were drawn using NUTS(diag_e) at Sat Jun  5 17:23:22 2021.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
&gt;</code></pre>
<p>The posterior means for the allele frequencies are indistinguishable from the maximum-likelihood estimates (<span class="math inline">\(p_a = 0.281\)</span>, <span class="math inline">\(p_b = 0.129\)</span>, and <span class="math inline">\(p_o = 0.59\)</span>), but we also have 95% credible intervals so that we have an assessment of how reliable the Bayesian estimates are. We also have estimates of the phenotype frequencies and their reliability. Getting estimates of the reliability for the allele frequencies from a likelihood analysis is possible, but it takes a fair amount of additional work.</p>
<h1 class="unnumbered" id="creative-commons-license">Creative Commons License</h1>
<p>These notes are licensed under the Creative Commons Attribution License. To view a copy of this license, visit https://creativecommons.org/licenses/by/4.0/ or send a letter to Creative Commons, 559 Nathan Abbott Way, Stanford, California 94305, USA.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>You’ll see in a week or a week and a half when we talk about analysis of population structure that we start discussing variation at many loci. But you’ll also see that in spite of discussing variation at many loci simultaneously, virtually all of the underlying mathematics is based on the properties of those loci considered one at a time.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>At each locus I’m talking about. Remember, I’m only talking about one locus at a time, unless I specifically say otherwise. We’ll see why this matters when I outline the ideas behind genome-wide association mapping.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p><span class="math inline">\(p_1 = 2(50)/200 = 0.5\)</span>, <span class="math inline">\(p_2 = (2(25) + 50)/200 = 0.5\)</span>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Although to be honest, we won’t see mating tables again after the first couple weeks of the semester.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>It would be easy enough to relax this assumption, but it makes the algebra more complicated without providing any new insight, so we won’t bother with relaxing it unless someone asks.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>We are also assuming that we’re looking at offspring genotypes at the zygote stage, so that there hasn’t been any opportunity for differential survival.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>If you’re interested, a pair of papers describing work on spore killer in <span><em>Neurospora</em></span> appeared in 2012 <span class="citation" data-cites="Hammond-etal-2012 Saupe-2012"></span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Not just the offspring from these matings.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Or the allele frequency is the same in generations that do overlap.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>There may be some that come reasonably close, but none that fulfill them <span><em>exactly</em></span>. There aren’t any populations of infinite size, for example.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Actually, there’s a ninth assumption that I didn’t mention. Everything I said here depends on the assumption that the locus we’re dealing with is autosomal. We can talk about what happens with sex-linked loci, if you want. But again, mostly what we get is algebraic complications without a lot of new insight.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>Chances are <span class="math inline">\(N_{aa}\)</span>, <span class="math inline">\(N_{ao}\)</span>, <span class="math inline">\(N_{bb}\)</span>, and <span class="math inline">\(N_{bo}\)</span> won’t be integers. That’s OK. Pretend that there really are fractional animals or plants in your sample and proceed.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>If you don’t know what maximum-likelihood estimates are, don’t worry. We’ll get to that in a moment.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>Yes, truth <span><em>is</em></span> sometimes stranger than fiction.<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>I should point out that this method <span><em>assumes</em></span> that genotypes are found in Hardy-Weinberg proportions.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>Since we’re making these genotype counts up, we can also pretend that it makes sense to have fractional numbers of genotypes.<a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>Technically, we treat <span class="math inline">\(\mbox{P}(K=k|p)\)</span> as a function of <span class="math inline">\(p\)</span>, find the value of <span class="math inline">\(p\)</span> that maximizes it, and call that value <span class="math inline">\(\hat p\)</span>.<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>You’ll be relieved to know that in this case, <span class="math inline">\(\hat p =
  k/N\)</span>.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>There’s another way I’d be happy to describe if you’re interested, but it’s a lot more complicated.<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p>A few of you may recognize that I didn’t choose that species entirely at random, even though the “data” I’m presenting here are entirely fanciful.<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>If we had prior information about the likely values of <span class="math inline">\(p\)</span>, we’d pick a different prior distribution to reflect our prior information. See the Summer Institute notes for more information, if you’re interested.<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22" role="doc-endnote"><p>You are probably thinking to yourself “The 1990s? That’s ancient history. Why is Holsinger making such a big deal about this” Please cut me a little slack. I know that most of you weren’t born in the early 90s, but I’d already taught this course two or three times by the time the paper I’m about to refer to was published.<a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23" role="doc-endnote"><p>This code and other <span><code>Stan</code></span> code used in the course can be found on the course web site by following the links associated with the corresponding lecture.<a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24" role="doc-endnote"><p>Your computer may appear to freeze after the message about avoiding recompilation. Don’t worry. It’s just thinking.<a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25" role="doc-endnote"><p>If you don’t understand why that’s different from a standard confidence interval, ask me about it.<a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26" role="doc-endnote"><p>This is almost the last time! I promise.<a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27" role="doc-endnote"><p>Assuming genotypes are in Hardy-Weinberg proportions. We’ll relax that assumption later.<a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
